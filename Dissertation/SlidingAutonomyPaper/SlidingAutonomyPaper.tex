\documentclass[lettersize, apacite, twoside, HRI]{apa_HRI}
% Required package for HRI journal format
\usepackage{times}
\usepackage{apacite}

% some very useful LaTeX packages include:
\usepackage{graphicx}  % Written by David Carlisle and Sebastian Rahtz
\usepackage{subfigure} % Written by Steven Douglas Cochran
                        % This package makes it easy to put subfigures
                        % in your figures. i.e., "figure 1a and 1b"
                        % Docs are in "Using Imported Graphics in LaTeX2e"
                        % by Keith Reckdahl which also documents the graphicx
                        % package (see above). subfigure.sty is already
                        % installed on most LaTeX systems. The latest version
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/subfigure/
                      
% The following are options that can be used in apa.cls but that are not used in apa_HRI
%\journal{Do not include -- hard coded}
%\volume{Volume 1, Number 3, pp. 1-16}
%\copnum{Do not include -- hard coded}
%\ccoppy{Do not include -- hardcoded}
%\ThreeLevelHeading  % HRI has a required heading style, and the HRI option overrides any of the apa.cls heading style commands

% The following are required options for the HRI journal format
\rightheader{Sliding Autonomy for UAV Path Planning}   % This should be the title, or a shortened version of the title if your title is long.
% \shorttitle{Beyond Fan-Out}    % Not used in HRI journal mode
\leftheader{Lin et al.}	  % For one or two authors, include both authors last names.  For three or more, use first author's last name et al.

% REQUIRED: paper title
\title{Sliding Autonomy for UAV Path Planning: Adding New Dimensions to Autonomy Management}

% REQUIRED: Author names and affiliations
% Note that authors from up to six affiliations can be added.  Beyond that, you are on your own.
% Group authors from the same affiliation together -- see example for two authors
%\author{Sole Author}
%\affiliation{Author Affiliation}
\author{Lanny~Lin, Michael~A.~Goodrich
, Spencer~Clark
}
\affiliation{Computer Science Department, Brigham Young University}
%\threeauthors{First Author}{Second Author}{Third Author} 
%\threeaffiliations{First Affiliation}{Second Affiliation}{Some Important Place}
%\fourauthors{First Author}{Second Author}{Third Author}{Fourth Author}
%\fouraffiliations{First Affiliation}{Second Affiliation}{Third Affiliation}{Fourth Affiliation}
%\fiveauthors{First Author}{Second Author}{Third Author}{Fourth Author}{Fifth Author}
%\fiveaffiliations{First Affiliation}{Second Affiliation}{Third Affiliation}{Fourth Affiliation}{Fifth Affiliation}
%\sixauthors{First Author}{Second Author}{Third Author}{Fourth Author}{Fifth Author}{Sixth Author}
%\sixaffiliations{First Affiliation}{Second Affiliation}{Third Affiliation}{Fourth Affiliation}{Fifth Affiliation}{Sixth Affiliation}

% REQUIRED: author addresses and email addresses
% Only the company/university/lab should be listed in affiliations above.
% The full address and email addresses will be included in a footnote.
% An address and email are only required for the corresponding author, but others may be included.

% REQUIRED: abstract
\abstract{
Increased use of autonomy also increases human-autonomy interaction and the need for humans to manage autonomy. We propose a new variation of the concept of sliding autonomy that is useful for planning problems over a spatial region. In this sliding autonomy approach, the user can influence the behavior of the autonomous system via three categories of input: information, spatial constraints, and temporal constraints. We present a set of user interface designs to implement sliding autonomy for UAV (Unmanned Aerial Vehicle) path planning to support Wilderness Search and Rescue (WiSAR). Interactivities along these new dimensions allow the user to allocate degrees of authority and flexibility to the robot's algorithms. We analyze how this approach fits in the integration challenge guidelines we identified in our prior work and evaluate the usefulness of the approach against manual and simple pattern path planning methods with a user study. Results show that the sliding autonomy approach performs significantly better than the other two methods without increasing the users' mental workload, and the performance of the human-autonomy team outperforms either human or autonomy working alone. We also discuss some interesting observations from the user study.
}

% REQUIRED: keywords
\keywords{human-robot interaction, unmanned aerial vehicles, path planning, navigation, adjustable autonomy, supervisory control, sliding autonomy}

% OPTIONAL: at submission time, you may include the following terms that may be useful for reviewers.
% These should be commented out in the final manuscript submrission. 
%\field{Technical, behavioral, design, or other}
%\contribution{article, short report, perspective, other (state)}
%\COI{Conflict of interest?  state}
%\uniqueness{State here (see CFP for required statement)}

%\acknowledgements{}

%% numbers option provides compact numerical references in the text. 
%\usepackage[sort,compress,numbers]{natbib}
%\usepackage{multicol}
%\usepackage[bookmarks=true]{hyperref}
%\usepackage{graphicx}
%\usepackage{amsmath}
%\usepackage{array}
%\usepackage{algpseudocode}
% 
%% \usepackage{caption}
%\usepackage{indentfirst}
%\usepackage{amsmath}
%\usepackage{multirow}
%\usepackage{array}
%\usepackage{algpseudocode}
%\usepackage{epstopdf}
%\newcommand{\rr}{\raggedright}
%\newcommand{\tn}{\tabularnewline}
%\newcommand{\shortcite}[1]{\cite{#1}}
%\newcommand{\degree}{\ensuremath{^\circ}}


% make the title area
\begin{document}
\maketitle

%=================================================================================
\section{Introduction}
\label{sec:Introduction6}

% First talk about need for autonomy management, especially for domain experts who don't know or care about how autonomy works
With the rapid advancement in technology, people are seeing increased use of autonomy to augment human abilities and support human decision-making in many application domains (e.g.,~\cite{Chun2010Limousine,Casper2003Human,Lin2010Supporting,Robins2009From}). At the same time, increased use of autonomy also means increased human-autonomy interaction and increased need for humans to manage autonomy~\cite{Bainbridge1983Ironies}. Even for so-called fully autonomous systems, human input can potentially improve the system's performance and safety. The humans in such interactions manage autonomy, because ``only people are held responsible for consequences (that is, only people can act as problem holders) and only people decide on how authority is delegated to automata''~\cite{Woods2006Joint,Bradshaw2013Seven}.

When humans manage autonomous systems, their managerial responsibilities often include monitoring the safety of the autonomous system, supervising autonomy to achieve acceptable performance, and making sure autonomy is working toward the collective goal of the overall system. In many emerging domains, the human operators are domain experts who can use domain-specific knowledge to assist the autonomous system when it deals with changing environments, uncertainty, and case-specific scenarios. Therefore, it is necessary to design tools and interfaces that enable human users to manage the autonomous behaviors of the system efficiently and effectively; such tools can improve task performance and the experience of the human operator in human-autonomy interaction. Wilderness Search and Rescue (WiSAR) is one such domain that could benefit from autonomy management tools when a mini-UAV (Unmanned Aerial Vehicle) is used in search.

% Discuss what application domain we apply this to, and the benefits.
Camera-equipped mini-UAVs can be useful tools in WiSAR operations by providing aerial imagery of a search area with the benefits of quick coverage of large areas, access to hard-to-reach areas, and lower cost than manned aircraft~\cite{Murphy2008Cooperative, Goodrich2008Supporting}. In fact Canadian mounties claim that they have successfully saved a person with a police drone in a recent rescue mission\footnote{http://www.theverge.com/2013/5/10/4318770/canada-draganflyer-drone-claims-first-life-saved-search-rescue}. UAV path planning is an important task because a good flight path can increase the probability of finding a missing person by making efficient use of the limited flying time. Various algorithms have been developed to support UAV path planning autonomy (e.g.,~\cite{Bourgault2003Coordinated, Lin2009UAV, Lin2014Hierarchical}). But how can a searcher incorporate domain expertise to manage UAV path planning autonomy efficiently and effectively without knowing how autonomy works behind the scene?
 
% Then we describe our approach.
We propose a new autonomy management approach where the user can influence the behavior of an autonomous system along three new dimensions: 1) \textbf{Information Representation}: information used by the robot is presented to the human in a human-readable form, and the human directly modifies this information to effect change in robot behavior; 2) \textbf{Spatial Constraints}: a human can add constraints or priorities to different spatial regions, thereby affecting how the robot plans and performs its task; and 3) \textbf{Temporal Constraints}: A human can impose time limits for a subtask or impose ordering constraints on a subtask. We refer to this approach as \textit{Sliding Autonomy} because, properly designed, it can allocate degrees of authority and flexibility to the robot's algorithms by adding or removing constraints, or by shaping input information. Indeed, we will explicitly use a \textbf{slider} as one GUI tool for managing UAV path planning. \

As the human modifies information, adds priorities, or changes constraints, the sliding autonomy tool shows immediately how those changes influence the UAV's plan. This instant feedback provides the searcher the ability to perform ``what-if'' analysis and see the causal effect between his/her action and changes in autonomous behavior. This allows an interactive approach where autonomous algorithms perform tasks that they are good at and humans do tasks that they are good at, but in a collaborative and interactive way that avoids the pitfalls of simple task allocation~\cite{Sheridan1992Telerobotics}. Properly done, the human-robot team should perform better than a human or robot working alone. 

% Briefly talk about existing approaches and what we propose, and why different.
Many approaches to autonomy management already exist and are called many different things, such as \textit{supervisory control}~\cite{Sheridan1992Telerobotics}, \textit{mixed-initiative}~\cite{Hearst1999Mixed}, \textit{collaborative control}~\cite{Fong1999Collaborative}, \textit{adjustable autonomy}~\cite{Dorais1998AdjustableAutonomy,Dorais2001Designing} (also referred to as \textit{sliding autonomy}~\cite{Dias2008SlidingAutonomy} or \textit{adaptive automation}~\cite{Rouse1988Adaptive,Kaber2001Design}). The approach we propose falls under the category of \textit{adjustable autonomy}. The three dimensions we identified are in addition to dimensions of \textit{adjustable autonomy} identified by Bradshaw et al.\, so we design tools and algorithms that operate in a particular place in Bradshaw's taxonomy~\cite{Bradshaw2004Dimensions}.

% Talk about that we extended our guidelines
In our previous work~\cite{Lin2010Supporting} we identified key elements of autonomy integration challenges along two dimensions: \textit{attributes of an intelligent system} (capability, information management, performance evaluation) and \textit{organizational scale} (individual versus group), which can serve as guidelines in designing autonomous components and autonomy management tools. In this paper we extend the guidelines to include attributes needed when human and autonomy work collaboratively and analyze how our proposed sliding autonomy approach fits in the guidelines. By applying sliding autonomy to the UAV path planning task, we argue that this approach:
\begin{itemize}
\item enables the domain expert user to incorporate information only available to or understandable by the expert;
\item is easy to understand without knowing how autonomy works behind the scene;
\item lets the human do what the human is good at (planning strategically and balancing performance tradeoffs) and autonomy do what autonomy is good at (planning tactically), resulting in better performance than human or autonomy working alone;
\item enables the user to align task goal (find the path that maximizes probability collected along the path) with system goal (finding the missing person quickly) when the user has more information or more up-to-date information than autonomy;
\item and improves human's experience during the human-autonomy interaction.
\end{itemize}

% We did user study to evaluate the approach. What are the results.
To evaluate the usefulness of the proposed approach, we performed a user study and compared the sliding autonomy method against two other planning methods (manual and simple pattern path planning) in two WiSAR scenarios (a synthetic scenario and a real scenario). We measured each user's performance with each method and also the user's performance on a secondary task (answer questions in a group chat window). Experiment results show that the sliding autonomy method performed significantly better than the manual or simple pattern planning methods with no increased mental workload. The human-autonomy team also performed better than the human or autonomy working alone.

% What does each section talk about?
In Section~\ref{sec:dimensions} we explain how the proposed approach fits into the extended autonomy design guidelines and describe how a user can manage autonomy along each of the three new dimensions in the context of UAV path planning. Section~\ref{sec:RelatedWork6} covers related work in literature. Section~\ref{sec:Hypotheses} lists our hypotheses followed by user study design in Section~\ref{sec:Design}. Then we present experiment results in Section~\ref{sec:Results} and discuss our observations in Section~\ref{sec:Discussion}. In Section~\ref{sec:Conclusions6} we conclude the paper and list possible future work.

%=================================================================================
\section{Autonomy Design Guidelines and New Dimensions}
\label{sec:dimensions}

%===================================================
\subsection{Autonomy Design Guidelines}

In our previous work~\cite{Lin2010Supporting} we organized the challenges of autonomy and management tool design along two dimensions: \textit{attributes of an intelligent system} (capability, information management, performance evaluation) and \textit{organizational scale} (individual versus group), which can serve as guidelines in designing autonomous components and autonomy management tools. Here we extend this table by adding a row in the middle describing what attributes are needed when multiple agents work collaboratively (see Figure~\ref{IChallenges}). A human-autonomy team working on the same task falls within this category. 

\begin{figure}
\centering
\includegraphics[width=5.5in]{IntegrationChallenges.JPG}
\caption{Autonomy integration challenges defined along two dimensions. Horizontal dimension: attributes of intelligence. Vertical dimension: organizational scale.}
\label{IChallenges}
\end{figure}

As an individual tool, an autonomous component needs to be able to perform a task (\textbf{Autonomy}); the operator can match capability to task according to the information available to the operator, which requires that autonomy can be interrupted, paused, aborted, and resumed (\textbf{Flexibility}); the performance is evaluated to match individual task goal. 

When a human-autonomy team works on the same task collaboratively, the autonomous component needs to provide interfaces so the human can interactively influence the autonomous behavior with human inputs (\textbf{Interactivity}); the human should be able to manage how autonomy works in order to jointly find a solution by utilizing information only available to the human and/or feed information to autonomy in a representation that autonomy can understand (\textbf{Manageability}); and when performance is evaluated, the human operator can judge whether the individual goal aligns with the collective goal of the system. 

As part of a larger distributed system, each autonomous component needs to be modular (\textbf{Modularity}), so they can be mixed and matched to support different user roles; information from various sources need to be combined and presented to one or multiple users in a \textbf{Fusion}; and performance of the system needs to be evaluated as a whole. 

This paper focuses on the middle row of the guidelines: intelligence of collaborative agents (human-autonomy team). The three dimensions we propose are ways path planning autonomy can be managed, and our path planner interface is designed to accept human inputs along the three dimensions to provide interactivity. The human can also incorporate information from various sources and influence the behavior of path planning autonomy by allocating degrees of authority and flexibility, making sure the task goal aligns with the ultimate goal of finding the missing person quickly.

%===================================================
\subsection{Information Representation Dimension}

Many path planning algorithms use a probability distribution map that shows where are likely places to find the missing person. We also designed our path planning algorithms to support a task-difficulty map: a spatial representation showing (one minus) sensor detection probability in different parts of the search region. For example, probability near the last known position (LKP) of the missing person is normally high (low task difficulty); and the probability of detecting the missing person in a dense vegetation area from camera footprints is normally low (high task difficulty). The objective of path planning is to find a path that maximize the detection probability of the missing person given a fixed flying time. 

These two maps are in human-readable form and are used directly by path planning autonomy. They can be systematically generated based on terrain features and vegetation data~\cite{Lin2010Bayesian, Lin2014Hierarchical}. However, the searcher likely wants to include his/her domain expertise (past experience, knowledge of the search region, etc.) and additional information (maybe new evidence found during the search) in the planning. These types of information are not directly understandable by autonomous algorithms, but the searcher can incorporate them into the probability distribution map and the task-difficulty map using map editing tools\footnote{Such as these tools at http://tech.lannyland.com/demos.html.}, thus influence the behavior of path planning autonomy.

Marking an area with high probability, the searcher indirectly tells the UAV to treat the area with high priority; marking an area with high task-difficulty, the UAV might make multiple passes over the area to search more thoroughly. The 3D surface in Figure~\ref{dimensions} shows an example probability distribution map where hills (red) indicate high probability and the flat area (blue) indicates low probability.

\begin{figure}
\centering
\includegraphics[width=3.5in]{Dimensions.JPG}
\caption{A screen capture of the sliding autonomy tool showing a 20 minute path. The 3D surface shows the probability distribution map. The UAV icon in the middle indicates the start point of the path segment and the sphere on the right indicate the end point.}
\label{dimensions}
\end{figure}

By managing information representation, the searcher can quickly figure out how his actions will affect the behavior of autonomy, even though he/she has no idea about how autonomy works behind the scene. Our interface supports autonomy management along this dimension. But we choose to not include it in the current user study (due to the one-hour limit per test subject) and leave the evaluation in a separate user study.

%===================================================
\subsection{Spatial Constraints Dimension}

The searcher can also influence the behavior of path planning autonomy by setting/changing spatial constraints. Spatial constraints can be in the forms of start/end points of the path segment or task-specific zones.

Setting an end point in an area is a way for the searcher to indirectly tell path planning autonomy that the area should have higher priority than other areas. For example, if a piece of clothing is found by the ground team, the searcher can force path planning autonomy to go visit that area by setting an end point there. Because the UAV must allocate part of the fix-length flight time to reach this specified area, some areas that had good payoffs before become costly and are no longer attractive to path planning autonomy. This way the searcher can also direct path planning autonomy to avoid certain areas (maybe the area has been thoroughly searched by the ground team). In Figure~\ref{dimensions}, the UAV icon in the middle indicates the start point of the path segment and the sphere on the right side indicates the desired end point. 

The end point can be dragged around the search region and path planning autonomy suggests different paths accordingly. When the end point is close to the start point, autonomy has greater authority and flexibility in creating paths. If the end point is far from the start point, authority and flexibility for autonomy is reduced because a major part of path planning is simply moving the UAV toward the end point with the shortest path.

A task-specific zone can be a no-fly zone, a coverage zone, or a sampling zone. A no-fly zone is a pretty straight-forward way to restrict the UAV from visiting certain areas. The decision might be for safety reasons or part of the searcher's strategic planning depending on resource allocation. A coverage zone requires the UAV to fully cover the area; a sampling zone only asks the UAV to collect a few sensor samples from the zone, so the visit can be very brief. A task-specific zone can be dragged around and the searcher can also change the shape and/or size of the zone to influence the path generated by autonomy.

The interactive ability to move the end point around (or changing the shape of the no-fly zone) and see immediately how the change would affect the UAV path recommended by path planning autonomy gives the user the power to perform ``what-if'' analysis. It also allows the user to see the causal effect between his/her action and changes in autonomous behavior.

Spatial constraints are easy to understand, so the searcher knows how these constraints will affect the behavior of path planning autonomy. By managing autonomy along this dimension, the searcher has another way to incorporate additional information to the path planning task, improve task performance, and align the task goal with the overall goal of finding the missing person quickly. 

In our user study we fixed the start point of the path to the center of the map because that was the last know position of the missing person. The searcher can set the end point for the current path segment anywhere on the map, and this end point automatically becomes the start point for the next path segment. Task-specific zone was not included in this user study (it was tested in a separate user study~\cite{Clark2013Hierarchical}).

%===================================================
\subsection{Temporal Constraints Dimension}

In the UAV path planning problem, temporal constraints can be time limit for a subtask (path segment), subtask ordering, or valid time window.

With the time limit constraint, the searcher can decide how much flight time to allocate to a path segment out of the total flight time. This enables the searcher to break the path planning task into multiple subtasks and then plan each path segment separately. In our interface design we let the searcher control time allocation to autonomy using a slider, and as the searcher moves the slider, path planning autonomy shows how suggested path segment changes respectively. Similar to the spatial constraints, this instant feedback enables ``what-if'' analysis and provides instant feedback on the causal effect between searcher action and changes in autonomous behavior.

For example, for a 60-minute total flight with an end point set to the probability hill on the right (Figure~\ref{dimensions}), the searcher can move the slider to set time limits and see immediately what path segment autonomy would suggest. The path segment shown is when 20 minutes are allocated. If the searcher is happy with the suggestion, he approves the path segment. The UAV moves to the end point in the path planner and ``vacuums up'' the probability along the path (how much can be vacuumed up is determined by the task-difficulty map). Then the searcher works with autonomy to plan path for the remaining 40 minutes. The two (or more) path segments are joined to form the final path.

Subtask ordering constraint adds temporal dependency to the subtasks (e.g., the sampling task must be flown before the coverage task). It lets the searcher directly specify priorities in different search areas. Valid time window constraint specifies at what time interval a subtask can be completed, so it is more restrictive than subtask ordering constraint.

By managing autonomy along the temporal constraint dimension, the searcher can break the path planning task into subtasks and incorporate additional information into the path planning task. The user study described in this paper includes the time limit constraint. Subtask ordering and valid time window constraints are evaluated in a separate user study~\cite{Clark2013Hierarchical}).

In the example shown in Figure~\ref{dimensions}, the combination of the information representation, end point constraint (spatial), and time limit constraint (temporal) allows the searcher to cover the middle area pretty well and then move to the search area on the right ready to search there. If no end point constraint is set, autonomy might decide to search the probability hill on the left with a low time limit or the hill at the bottom with a high time limit. If more flight time is allocated with the set end point, autonomy might start searching the area on the right. Instant feed back on path changes when the search moves the endpoint or varies the time limit lets the searcher interactively review multiple options and select the path segment that fits best with his/her strategic planning. This design enables human to plan more strategically (prioritizing areas in the entire search region) while autonomy works more tactically (covering the current search area well), using strengths of each when they work collaboratively. Ideally such a human-autonomy team should work better than either human or autonomy working alone.

%=================================================================================
\section{Related Work}
\label{sec:RelatedWork6}

Drucker defines automation as a ``concept of the organization of work~\cite{Drucker2006Practice}.'' Goodrich and Schultz define the HRI problem as ``understanding and shaping the interactions between one or more humans and one or more robots''~\cite{Goodrich2007HRISurvey}. They also specified robot-assisted search and rescue as a key area for HRI research. In their 1978 seminal paper, Sheridan and Verplank propose the idea of a \textit{level of autonomy} spectrum, with full teleoperation at one end and full autonomy at the other~\cite{Sheridan1978Human}. In the middle, the robot could suggest actions to humans or make decisions before informing humans. Parasuraman et al.\ extended this one-dimensional spectrum to four different broad functions: information acquisition, analysis, decision selection, and action implementation~\cite{Parasuraman2000Model}. Sheridan proposes \textit{supervisory control}, in which a human divides the task into a sequence of subtasks that the robot is capable of performing, and the human then provides guidance when the autonomous system cannot solve a problem on its own~\cite{Sheridan1992Telerobotics}. In contrast to the top-down philosophy of supervisory control, a \textit{mixed-initiative} approach advocates the idea of dynamically shifting tasks when necessary~\cite{Hearst1999Mixed}. \textit{Collaborative control}, which can be thought of as an instance of mixed-initiative interaction, is a robot-centric model; instead of the human always being in-charge, the robot is treated as a peer and can make requests to humans through dialogs~\cite{Fong1999Collaborative}. \textit{Adjustable autonomy}~\cite{Dorais2001Designing} (also referred to as \textit{sliding autonomy}~\cite{Dias2008SlidingAutonomy} or \textit{adaptive automation}~\cite{Rouse1988Adaptive}) is another type of mixed-initiative interaction, one that enables the human-automation team to dynamically and adaptively allocate functions and tasks among team members. 

Dorais et al.\ discuss a framework for human-centered autonomous systems for a manned Mars mission~\cite{Dorais1998AdjustableAutonomy}. The system enables users to interact with these systems at an appropriate level of control but minimize the necessity for such interaction. Bradshaw et al.\ discuss principles and pitfalls of adjustable autonomy and human-centered teamwork, and then present study results on so-called ``work practice modeling'' and human-agent collaboration in space applications~\cite{Bradshaw2003AdjustableAutonomy}. Kaber et al.\ describe an experiment simulating an air traffic control task where manual control was compared to Adaptive Automation (AA)~\cite{Kaber2005Adaptive}. Results suggest that humans perform better with AA applied to sensory and psychomotor information-processing functions than with AA applied to cognitive functions; these results also suggest that AA is superior to completely manual control. Brookshire et al.\ present preliminary results for applying sliding autonomy to a team of robots performing coordinated assembling work to help the system recover from unexpected errors and to thereby increase system efficiency~\cite{Brookshire2004Preliminary}. Dias et al.\ identified six key capabilities that are essential for overcoming challenges in enabling sliding autonomy in peer-to-peer human-robot teams~\cite{Dias2008SlidingAutonomy}. Bradshaw et al.\ propose two dimensions of Adjustable Autonomy (descriptive and prescriptive) to address the two senses of autonomy (self-sufficiency and self-directedness) and discuss how permissions, obligations, possibilities, and capabilities can be adjusted~\cite{Bradshaw2004Dimensions}. Bradshaw et al.\ also summarized some widespread misconceptions on autonomy and listed seven deadly myths of ``autonomous systems''~\cite{Bradshaw2013Seven}.

The human is an integral part of the human-autonomy team. When working with autonomy, the human often takes on the supervisor role. Bainbridge points out that automation requires the human operator to take additional management responsibilities~\cite{Bainbridge1983Ironies}, and Sartar identified two automation management policies: \textit{management by consent} and \textit{management by exception}, defining whether the human always retain authority or can the system take initiativein~\cite{Sarter1998Making}. For complex automation, the human tends to rely on his/her \textit{mental models}~\cite{Norman1983Some} to manage the system. 

UAV technology has emerged as a promising tool in supporting WiSAR~\cite{Murphy2008Cooperative,Bourgault2003Coordinated}. The goal of our research is to support fielded missions in the spirit of Murphy's work~\cite{Casper2003Human}. Many path planning algorithms in the literature address obstacle avoidance while planning a path to reach a destination using A*~\cite{Quigley2005Towards}, LRTA*~\cite{Howlett2006Learning}, D*~\cite{Stentz1997Optimal}, Voroni diagrams~\cite{Bortoff2000Path,Beard2005Autonomous}, or probability roadmaps and rapidly-exploring random tree (RRTs)~\cite{Pettersson2006Probabilistic}. 
%Hierarchical heuristics approaches were also developed, such as Hierarchical A* (HA*) by Holte et al.\ ~\cite{Holte1996Hierarchical}, hierarchical task-based real-time path planning by Naveed et al.\ ~\cite{Meuleau2007Hierarchical}, and Hierarchical-AO* (HiAO*) by Meuleau and Brafman~\cite{Naveed2010Hierarchical}. 
Bourgault et al.\ \cite{Bourgault2004Coordinated,Bourgault2006Optimal} describe how to use a Bayesian model to create paths for a single UAV or multiple coordinated UAVs to maximize the amount of probability accumulated by the UAV sensors. The algorithms we used in this paper are algorithms designed from our previous work~\cite{Lin2009UAV,Lin2014Hierarchical} using techniques such as global warming technique, convolution, Gaussian mixture models, and Evolutionary Algorithm.

%=================================================================================	
\section{Hypotheses} 
\label{sec:Hypotheses}

A user study is performed to evaluate the usefulness of the sliding autonomy approach. More specifically we verify the following hypotheses:

H1: The sliding autonomy method performs better than either the manual path planning method or a semi-autonomous simple pattern path planning method in both low information and high information scenarios.

H2: The sliding autonomy method performs better than autonomy working alone in both low information and high information scenarios.

H3: The sliding autonomy method does not increase the mental workload of the operator when compared against manual and pattern methods.

%=================================================================================	
\section{User Study Design} 
\label{sec:Design}

\begin{figure}
\centering
\includegraphics[width=3.5in]{UserStudy.JPG}
\caption{Top: User study simulation interface with sliding autonomy method showing the probability distribution map for scenario 1. Middle left: Probability distribution map for scenario 2. Middle Right: Task-difficulty map for scenario 2. Bottom: The three patterns available to user in pattern planning mode, spiral, lawnmower, and line.}
\label{UserStudy}
\end{figure}

We performed a 2$\times$3 within-subject design with 2 scenarios (easy vs difficult) and 3 planning methods (manual, pattern, and sliding autonomy). All participants completed all 6 exercises. The order of the scenarios and planning methods is counterbalanced to reduce learning effect. We recruited a total of 26 college students (14 males and 12 females) between the age of 19 and 30 (average 22.89). 

After the demographic survey, each participant completes four 5-minute non-skippable training exercises (one for each planning method with no task-difficulty map, and one for manual with a task-difficulty map) and then completes the 6 exercises. Each participant has up to 5 minutes for each exercise. Once the participant is happy with the path generated, he/she can finish the exercise early. We choose this design because we do not want the user to put all effort into completing the secondary task once he/she considers the primary task completed, which would skew the measurements on secondary task performance. At the end of each exercise, the participant completes a NASA TLX survey. Then at the end, the participant fills out a survey describing his/her subjective preference with the three planning methods.


%===================================================
\subsection{Simulation Environment}

The user study is conducted in a 3D simulation environment (see Figure~\ref{UserStudy} top) where both the probability distribution map and the task-difficulty map are displayed as 3D surfaces with a color map (red means high and blue means low). The user can switch between the two maps at any time and rotate/pan/zoom a map at will. The UAV is a hexacopter capable of flying in all directions or hover in the same spot.

With the \textbf{manual} planning method, the user flies the UAV with arrow keys in a sped up fashion. The user can switch between two flying modes (turn and strafe) and four camera views (global, behind, bird's eye, and free form). The user can also pause/resume the flight for the secondary task or better planning.

With the \textbf{pattern} planning method, the user chooses from spiral, lawnmower, and line patterns (see Figure~\ref{UserStudy} bottom) and join these patterns to form the final path. Cursor position marks the end of the path segment and determines the size of the pattern. The user can also undo the last path segment planned. This planning method is ``semi-autonomous'' because the patterns are generated automatically without manually setting waypoints.

With the \textbf{sliding autonomy} method (see Figure~\ref{UserStudy} top), the user can set an end point (optional), and then drag the left slider to change the amount of time allocated to autonomy. Path suggested by autonomy changes as the slider moves. The slider's max value always reflects the remaining flight time (in minute). If the user is happy with the current path segment, he/she approves it, the UAV moves to the end of the path segment, and the process repeats until all flight time has been planned. The algorithm used is the LHC-GW-CONV algorithm~\cite{Lin2009UAV, Lin2014Hierarchical}, because it is the fastest algorithm out of all the algorithms we designed.

With all three planning methods, the user can choose to start over at any time during the exercise, and can restart as many times as exercise time allows. We record the best path out of all tries.

%===================================================
\subsection{Scenarios}

The user study contains two WiSAR scenarios, a synthetic case (see Figure~\ref{UserStudy} top) with no task-difficulty map (assuming uniform detection probability), and a real WiSAR scenario (see Figure~\ref{UserStudy} middle) with a task-difficulty map, in which An elderly couple was reported missing near the Grayson Highlands State Park in Virginia~\cite{Koester2008Lost}\footnote{The probability distribution map used for this scenario (Figure~\ref{UserStudy} middle left) was generated using a Bayesian model~\cite{Lin2010Bayesian}. The map has been evaluated at George Mason University's MapScore web portal~\cite{Twardy2012MapScore} and performed better than most other models evaluated, scoring 0.8184 on a [-1,1] scale where the higher the score the better. http://sarbayes.org/projects/. The task-difficulty map (Figure~\ref{UserStudy} middle right) was generated using vegetation density data downloaded from the USGS web site and categorized into three difficulty levels (sparse, medium, and dense, with detection probability of 100\%, 66.67\%, and 33.33\% respectively).}.

Scenario 2 is clearly more complicated than scenario 1 because the user also has to consider the different detection probability defined by the task-difficulty map. We refer to scenario 2 as the high information scenario and scenario 1 as the low information scenario.

%===================================================
\subsection{Secondary Task}

In each exercise, each participant also performs a secondary task, so we can measure user's mental workload. In a group chat window (see Figure~\ref{UserStudy} top) when the user's code name is called, the user has to type answers to simple questions. Roughly every 3 seconds a message is sent to the chat window, and every 5th message asks the user a simple question (4 per minute). For the same scenario and the same planning method, all users received the same set of chat messages.

We choose to use a group chat window as the secondary task because this is typical in real SAR operations. We also designed the chat messages to simulate a real WiSAR search. The user is asked to acknowledge connection and report path planning status periodically. This design ensures that the secondary task is ecologically valid~\cite{Vicente1997Should,Rasmussen1994Cognitive}.

%===================================================
\subsection{Measures}

We use the following five measurements for the primary path planning task:

\begin{itemize}
\item \textbf{Percent score}: In each exercise, an exercise score is computed by summing the amount of probability collected by the UAV if it followed the path planned. The user's best score for each exercise (out of multiple tries) is normalized by dividing the best score from all users for the same scenario to compute the percent score. This way we can compare planning methods across scenarios.
\item \textbf{Time spent}: How much time is spent with each exercise.
\item \textbf{Try count}: How many times the user tried in each exercise. Note that because the manual planning method takes much longer time to plan a path than the other two methods by design, this measurement is used mainly to compare between the pattern and sliding autonomy planning methods.
\item \textbf{Mouse clicks per try}: How many times the user left-clicked the mouse within a try. Again, this measurement is used to compare pattern and sliding autonomy planning methods because manual planning methods does not require a lot of mouse clicks by design.
\item \textbf{NASA-TLX raw score}: The sum of user subjective evaluation of cognitive workload in six dimensions normalized to a 100-point scale. 
\end{itemize}

The following two measurements are used for the secondary task:
\begin{itemize}
\item \textbf{Percent of questions missed}: What percentage of questions directed to the user were missed before user completed the exercise. Here we do not measure the percent of questions answered correctly because all the questions are very simple and all users answered the questions correctly.
\item \textbf{Chat latency}: The number of seconds between the time a question was presented to the user and the time when the user answered the question.
\end{itemize}

%=================================================================================	
\section{Results and Analysis} 
\label{sec:Results}

We analyzed user study data with a mixed measures analysis of variance (ANOVA) and report results in this section.

%===================================================
\subsection{Comparing Across Scenarios}

During the user study, each participant worked through two WiSAR scenarios. In scenario 1 (low information) no task-difficulty map is used. In scenario 2 (high information) because partial detection is enforced, the amount of probability that can be collected (exercise score) in scenario 2 is much lower than in scenario 1. In order to show a fair comparison across scenarios, we use percent score instead, which compares the participant's score to the best performing participant's score in the same scenario.

No statistically significant differences were found across scenarios for percent score, time spent, and try count. Average Percent score is very close in both scenarios (about 75\%) because we normalize exercise scores against the highest user score for the same scenario. There is a slight difference of 26 seconds in average time spent, which is not significant compared to the 300 seconds given for each exercise. Average try count in both scenarios are also close enough (3.08 and 2.67).

Mouse clicks per try for the two scenarios are significantly different ($F[1,25]= 28.65, p<.0001$) indicating scenario 2 required more physical work from each participant than scenario 1. This result matches the difficulty of the two scenarios where each participant created more path segments with the pattern and sliding autonomy planning methods in scenario 2 because it uses a complex task-difficulty map.

NASA TLX scores are also significantly different ($F[1,25]= 31.35, p<.0001$) between the two scenarios where the average score difference is 9.98 (out of a total of 100 points), almost a full ``pip'' on the TLX survey, indicating that on average each participant felt his/her cognitive workload was much higher in the high information scenario.

The percent of questions missed is almost identical between scenarios (54.88\% and 54.90\%), and the chat latency is also very close (10.39 and 11.17 seconds). This shows that participants on average performed about the same with the secondary task across scenarios.

If we look at the performance of only the sliding autonomy planning method across scenarios, results follow the same trend.

%===================================================
\subsection{Comparing Across Planning Methods}

For each scenario, three path planning methods were used (manual, pattern, and sliding autonomy). Table~\ref{AcrossMethods} lists comparison among these three methods. 

Percent score differences are statistically significant ($F[2,50]= 223.03, p<.0001$) with sliding autonomy (94.60\%) performing better than pattern (72.75\%) and manual (59.40\%) performing the worst. As shown in Figure~\ref{PerformanceDifference}, this trend is also clear in both scenario 1 and 2 individually. Therefore, user study results show strong support for our first hypothesis: sliding autonomy method performs better than either the manual method or the pattern method in both low information and high information scenarios.

\begin{table}
\caption{Comparing across planning methods (SE stands for standard error)}
	\centering
		\begin{tabular}
			{|l|c|c|c|c|c|}
			\hline
			& M & P & SA & SE & Significance \\			
			\hline
			\% Score & 59.40 & 72.75 & 94.60 & 1.39 & $\boldsymbol{F[2,50]=223.03, p<.0001}$ \\
			Time spent & 243.35 & 240.02 & 228.37 & 12.06 & $F[2,50]=1.16, p=.32$ \\
			Try count & 1.75 & 3.56 & 3.31 & 0.43 & $F[2,50]=9.47, p=.0003$ \\
			Clicks/try & 13.01 & 35.64 & 25.58 & 2.90 & $\boldsymbol{F[2,50]=19.47, p<.0001}$ \\
			NASA TLX & 61.51 & 49.18 & 48.86 & 2.81 & $\boldsymbol{F[2,50]=14.15, p<.0001}$ \\
			\hline
			\% Q. missed & 52.94 & 56.69 & 55.04 & 5.17 & $F[2,50]=1.26, p=.29$ \\
			Chat latency & 10.39 & 11.17 & 10.92 & 0.65 & $F[2,50]=0.46, p=.63$ \\
			\hline			
			\multicolumn{6}{c}{}  % This is a patch to fix a bug in the table command.									
		\end{tabular}
\label{AcrossMethods}
\end{table}

\begin{figure}
\centering
\includegraphics[width=3.5in]{PerformanceDifference.JPG}
\caption{Performance difference for three path planning methods.}
\label{PerformanceDifference}
\end{figure}

Statistically significant differences were also found in mouse clicks per try ($F[2,50]=19.47, p<.0001$). The manual method uses arrow keys to fly the UAV around and only uses mouse clicks when switching camera modes or stop the timer in order to perform the secondary task. By design, this method does not use a lot of mouse clicks. Pattern and sliding autonomy methods both use mouse clicks for the actual path planning task, and the pattern method clearly generated more mouse clicks per try (35.64) than the sliding autonomy method (25.58). Two factors might have contributed to this difference, first one being that the pattern method allows undoes while the sliding autonomy method does not support this function. Also with the sliding autonomy method a participant can drag the slider and see different suggestions from path planning autonomy, which does not require a lot of mouse clicks.

NASA TLX raw scores show significant differences ($F[2,50]=14.15, p<.0001$) among the three methods, with the manual method showing the highest cognitive mental workload (61.51), a full ``pip'' more than the other two methods on the TLX survey. However, the average score difference between the pattern method and the sliding autonomy method is small (49.18 vs. 48.86). Figure~\ref{NASATLX} shows the box plots of the NASA TLX scores for each scenario. Participants felt that the pattern method and the sliding autonomy method required about the same amount of cognitive mental workload in each scenario, and the manual method required a lot more mental workload in both scenarios.

\begin{figure}
\centering
\includegraphics[width=3.5in]{NASATLXBoxPlot.JPG}
\caption{Box plots of the NASA TLX scores for each scenario.}
\label{NASATLX}
\end{figure}

For all three planning methods, participants performed about the same on the secondary task, as shown by percent of questions missed and chat latency in Table~\ref{AcrossMethods}. Combining this with percent score and NASA TLX we can conclude that sliding autonomy performed best without increasing participants' mental workload, which support our third hypothesis: Sliding autonomy method does not increase the mental workload of the operator when compared against manual and pattern methods.

\begin{figure}
\centering
\includegraphics[width=3.5in]{PerformanceMarkers.JPG}
\caption{Comparing sliding autonomy performance against various markers.}
\label{PerformanceMarkers}
\end{figure}

If a participant allocates the entire flight time (60 minutes) to path planning autonomy (LHC-GW-CONV algorithm), the path is generated by full autonomy without any human input. The percent score for this path would be 96.13\% for scenario 1 and 78.83\% for scenario 2. This is better than the average performance of the manual and pattern methods in both scenarios as shown in Figure~\ref{PerformanceMarkers}. If we compare each person's percent score against full autonomy for all 26 participants, in scenario 1, none could outperform full autonomy using the manual or pattern methods, but 23 (88.46\%) were able to perform better with sliding autonomy (human-autonomy team). In scenario 2, no one did better using the manual method, 5 (19.23\%) did outperform full autonomy using the pattern method, and 24 (92.31\%) were able to beat full autonomy using the sliding autonomy method. Table~\ref{CompareToFullAutonomy} summarizes the comparison. User study results clearly show that the human inputs made significant differences in path planning performnace and human-autonomy team outperformed autonomy working alone. This also strongly supports our second hypothesis: Sliding autonomy method performs better than autonomy working alone in both low information and high information scenarios.

\begin{table}
\caption{Percent of participants outperforming autonomy with each method}
%\small
	\centering
		\begin{tabular}
			{|l|c|c|c|}
			\hline
			 & Manual & Pattern & Sliding Autonomy \\
			\hline
			Scenario 1 (Low) & 0\% & 0\% & \textbf{88.46\%} \\
			\hline
			Scenario 2 (High) & 0\% & 19.23\% & \textbf{92.31\%} \\
			\hline			
			\multicolumn{4}{c}{}  % This is a patch to fix a bug in the table command.									
		\end{tabular}
%\vspace*{-2ex}
\label{CompareToFullAutonomy}
\end{table}

%===================================================
\subsection{Additional Factors}

We also performed ANOVA analysis on some additional factors that might create differences: gender, experience in video games, order of the scenarios, and whether participants used full autonomy with the sliding autonomy method. No significant differences were found for these factors overall, across scenarios, or across methods. There is also no significant correlation (-0.23) between percent of questions missed in the secondary task and the NASA TLX raw scores.

%=================================================================================	
\section{Discussion} 
\label{sec:Discussion}

%===================================================
\subsection{Planning methods Characteristics}

\noindent \textit{Manual Method}

With the manual method, the user uses arrow keys to move the UAV around to create a path, so by design the method is very intuitive, flexible, and requires more physical interactions (keyboard, not mouse clicks). But in order to plan a 60-minute path in 2 minutes, the UAV has to move very quickly in the simulation environment. We made sure each user can complete at least two tries using this method while performing the secondary task simultaneously. High UAV speed makes it harder to navigate accurately. Many participants called the arrow keys too ``sensitive'' and recommended slowing down the UAV. 

Because of the time pressure, the path planning task is more of a continuous process. Therefore, when errors are made, it is too costly to start over (we did not provide an undo function). The user also does not have the luxury to pause the planning in order to think through strategies in his/her head; it has to be done while the user is moving the UAV around. Naturally, when this continuous process is frequently interrupted by the secondary task where the user has to pause planning and answer questions in the group chat window, user frustration goes high. 

More physical work, higher frustration, and low performance score are the main factors contributing to a much higher NASA TLX score for the manual method. Although this planning method supports four camera views and two flying modes, most participants chose to stick with free form view where the entire search region is displayed and with strafe mode to avoid getting confused with UAV orientation. During training, participants actually had one extra exercise with the manual method, but this method still performed the worst.

~\\ \noindent \textit{Pattern Method}

With the pattern method, the user joins a mixture of three patterns (spiral, lawnmower, and line) together to form the final path. This is more of an episodic process, so it is very easy to pause in the middle of the planning and shift attention to the secondary task. There is also less time pressure because the user can quickly plan for the remaining time with just one big spiral (or lawnmower) in one click. Therefore, the user has plenty of time to try many times with different strategies.

In the post user study survey, many participants commented that with the spiral and lawnmower pattern it is really easy to run out of time. They suggested adding the ability to allocate time to the patterns similar to the sliding autonomy method. This means that with this method, a user enjoys the systematic coverage of an area but has a hard time estimating how much time it takes the UAV to cover the area following the pattern. Several participants also suggested adding more patterns to the method. 

The pattern method is the only method supporting undoes. This ability surely had impacts on number of mouse clicks per try and participants' preference over the three planning methods. Another interesting observation is that participants seemed to be overly optimistic about their performance using the pattern method. For example, although sliding autonomy performed better than pattern in all scenarios for all participants, in 46.15\% of the times, participants rated pattern as performing better than sliding autonomy in NASA TLX scores; and also in the post user study survey, 26.92\% participants (not the majority, but over a quarter of the population) actually believed the pattern method creates best paths.

~\\ \noindent \textit{Sliding Autonomy Method}

Similar to the pattern method, the sliding autonomy method is also an episodic process. Therefore, stopping in the middle of the planning to answer questions for the secondary task was easy. And it only takes a few clicks to let autonomy plan path for the remaining time, so there is not much time pressure and the user can have many tries. 

Because the user does not know how autonomy works behind the scene, many participants were surprised by the path recommended by autonomy, and feel that autonomy did not do what they had tell it to do. For example, when a user sets the end point in region A, autonomy might plan a path that spends most of time in a seemingly unrelated region B and only goes toward region A at the end of the path, because such a path is more efficient (scores higher). In such cases, the slider becomes the only tool that lets the user ``force'' autonomy to do what the user wants, and path planning turns into a fight between the human and autonomy. However, the instant feedback (displaying path and the predicted ``vacuuming effect'') does help the user figure out why autonomy would suggest something different, and some participants were glad that autonomy suggested better paths they had not considered. 

Most participants were generally happy with the path segment recommended by autonomy covering a local region, even when the region is in an irregular shape (not a circle or rectangle). Many participants also expressed that they did not have enough control over the path generation and recommended adding the ability to include constraints such as ``middle points'' where the path segment has to go through these middle points. In fact, such ``middle points'' can already be achieved with the current method by setting end points. Several participants complained that this method does not have the undo function. They also wanted the ability to see how suggested path changes when the end point is moved around, which is an idea worth exploring because it allows the user to not only slide along the time allocation dimension, but also slide along the constraints dimension and see instant feedback. With both the pattern and sliding autonomy methods, many participants expressed the desire to be able to modify the path after it is generated.

~\\ \noindent \textit{User Preferences}

In scenario 2 where a task-difficulty map was used, because the probability map is similar to a unimodal distribution (see middle portion of Figure~\ref{UserStudy}, most participants chose to first cover the probability hill using the probability distribution map, and then planned the remaining path using only the task-difficulty map view in all three methods. If the probability distribution map is more complex with many probability hills, then likely the user will be switching between the two maps back and forth in order to incorporate information. Some suggested showing both maps side by side or have a way to combine the two maps into one. These ideas are worth exploring in future user studies.

In the post user study survey, the majority of the participants think manual is the easiest to learn (53.85\%), pattern is the easiest to use (57.69\%), and sliding autonomy performed the best (65.38\%). However, most participants preferred the pattern method (69.23\%) out of all three. We believe the inability to undo, not able to move the end point once path is suggested, and the second slider in the interface (which we will discuss in a later section) all had negetive impacts on participants' preference over the sliding autonomy method. Once these functions are in place, the sliding autonomy method will become more preferrable than the pattern method.

%===================================================
\subsection{Reliance on autonomy}

The algorithm we used for the sliding autonomy method is the LHC-GW-CONV algorithm. We selected this algorithm because of its fast speed. If speed is not a concern, then the Evolution Algorithm (EA) we developed~\cite{Lin2009UAV} can autonomously generate even better paths. For example, the percent score for EA would be 96.36\% for scenario 1 and 96.54\% for scenario 2. In scenario 1, the score is only slighly better than full autonomy in sliding autonomy (96.13\%), but in scenario 2, the score is much better than full autonomy (78.83\%). We also used the sliding autononomy method and generated paths for both scenario 1 and 2 with only one human input, an end point. Using the best score out of 3 tries (roughly equal to the average number of tries in the user study), we also computed the percent score for this autonomy+1 human input approach: 99.47\% for scenario 1 and 98.58\% for scenario 2. Using the EA and Autonomy+1 score as additional markers, we plotted participants average performance in each scenario against these markers. Figure~\ref{PerformanceMarkers} shows the result.

First, sliding autonomy (human-autonomy team) outperformed autonomy (LHC-GW-CONV algorithm) in both scenarios. Sliding autonomy also outperformed EA in scenario 1 (low information). In scenario 2, the performance of sliding autonomy is not very far from EA (5.36\%), and the difference is even smaller (1.85\%) when averaged over both scenarios. However, the most interesting observation is that autonomy+1 actually outperformed all others in both scenarios (99.47\% for scenario 1 and 98.58\% for scenario 2). Although a few participants did score higher than autonomy+1, the difference is less than 1.5\%. Table~\ref{CompareToMarkers} lists what percentage of participants outperformed full autonomy, EA, and autonomy+1.

\begin{table}
\caption{Percent of participants outperforming autonomy performance markers}
%\small
	\centering
		\begin{tabular}
			{|l|c|c|c|}
			\hline
			 & Autonomy & EA & Autonomy+1 \\
			\hline
			Scenario 1 (Low) & \textbf{88.46\%} & \textbf{88.46\%} & 7.69\% \\
			\hline
			Scenario 2 (High) & \textbf{92.31\%} & 26.92\% & 15.38\% \\
			\hline
			\multicolumn{4}{c}{}  % This is a patch to fix a bug in the table command.						
		\end{tabular}
\label{CompareToMarkers}
%\vspace*{-2ex}
\end{table}

What Figure~\ref{PerformanceMarkers} suggests is that with the sliding autonomy method, it does not need a lot of human inputs to perform really well. Instead of spending the effort creating many path segments and set many end points, it is probably more rewarding to search for the right region to set just one or two constraints. However, 88.68\% of participants gave more than 1 input when they used sliding autonomy (81.13\% for 2 inputs and 69.81\% for 3 inputs). In the post user study survey, only 46.15\% participants acknowledged using full autonomy with the sliding autonomy method. These numbers indicate the human's under-reliance on autonomy. When using the sliding autonomy method, a good strategy is actually to start with full autonomy (as the worst scenario) and then see how additional human inputs can improve the path.

%Moray~\cite{Moray1999Mental} provides a good summary of how mental models are used and proposes that mental models ``allow operators to think about causal structures and functions in systems which they must control....'' Goodrich and Boer present a case study of Adaptive Cruise Control design and explain how an automobile driver can switch among multiple mental models and use different management strategies~\cite{Goodrich2002Multiple, Goodrich2003Model}. 

Lee and See propose that because people respond to technology socially, trust guides reliance when unanticipated situations make it impractical or impossible to understand automation~\cite{Lee2004Trust}, and defined \textit{distrust}, ``trust falls short of the automation's capabilities'', and \textit{overtrust}, ``trust exceeds system capabilities''. Bradshaw et al.\ \cite{Bradshaw2013Seven} had similar definitions and used the term \textit{under-reliance} for distrust, instead. Both suggested that trust in automation should be ``calibrated''. Hoffman et al.\ \cite{Hoffman2013Trust} suggest ``active exploration for trusting''(AET) and hope this approach can promote both trust ``calibration'' and appropriate reliance. We believe that the sliding autonomy approach we propose can be useful in this aspect, because as the user is moving the slider, he/she is calibrating his/her reliance on path planning autonomy. In our user study, all participants only had 30 minutes of training before using the sliding autonomy method. We speculate that as the user gets more familiar with the sliding autonomy approach in the long run, he/she would be able to calibrate reliance better. However, validation of this claim is beyond the scope of this paper and will be part of a future long-term user study.

When more complicated probability distribution map and task-difficulty map are used, it is possible that the human user will see more value in the sliding autonomy approach because combining this much information in human mind and then decide tradeoffs in path planning required much more computation. And when the human user finds himself/herself incapable of such tasks, he/she might rely on autonomy to help solve the puzzle, and the sliding autonomy approach becomes more useful in calibrating reliance. Validating this hypothesis is another natural extension of the present work.

%===================================================
\subsection{Why human-autonomy team performs better?}

User study results show that the human-autonomy team outperformed either human or autonomy working along. But how were they able to achieve this? We believe that the reason is: the sliding autonomy approach enabled the human to focus on what human is good at and autonomy to focus on what autonomy is good at. Bradshaw et al.\ pointed out in~\cite{Bradshaw2013Seven}: ``Humans, though fallible, are functionally rich in reasoning strategies and their powers of observation, learning, and sensitivity to context.'' Our observation suggests that human is really good on two things: planning strategically and recognize bad path segments.

The sliding autonomy method lets the user plan at a higher abstract level by specifying priorities in search sub-regions and how well each sub-region should be covered. Then how to cover the sub-region well given a fixed flight time is left for autonomy to handle. Autonomy, on the other hand can generate a path that covers a sub-region (or some nearby sub-regions) precisely and quickly, and can handle all kinds of irregular sub-region shapes. Therefore, the sliding autonomy method combines the strengths of both human and autonomy.

A human user is also very good at recognizing bad moves in solutions suggested by autonomy. The sliding autonomy approach enables the human user to select from a bunch of suggested paths, selecting a path segment with fewer bad moves (which might not actually be bad in autonomy's perspective with just the current path segment) will probably increase the chance of a good final path. So again, the sliding approach takes advantage of the strengths of both human and autonomy.

%===================================================
\subsection{Why similar secondary task performance in all three methods?}

The pattern and sliding autonomy methods are episodic, suggesting that it is easier for the user to pause planning and shift attention to the secondary task of answering questions in the group chat window. However, user study data show that there is no significant differences in secondary task performance across all three path planning methods.

The manual method requires a lot of continuous keyboard interaction (great physical demand and temporal demand) to move the UAV around. However, it does not actually require much mental demand and effort because the planning process is more sporadic and spontaneous. If a mistake is made, because there is no way to correct it, the user quickly stops worrying about it and moves on. The low mental demand and effort make monitoring the group chat window an easy task, even though switching back and forth between primary task and secondary task is very frustrating.

With the pattern and sliding autonomy methods, path planning is more like piecing together a puzzle. The user is deeply drawn into problem solving, constantly comparing tradeoffs, which actually requires more mental involvement. With the sliding autonomy method, the user is interacting with complicated algorithms, so while planning a path, the user is also trying to build a mental model of how autonomy works. Therefore, the user actually paid less attention to the secondary task. Fighting with autonomy when human and autonomy had disagreements also drew user attention away from the group chat window. But when the group chat window catches the user's attention, he/she can perform the secondary task leisurely.

David Woods and Eric Hollnagel describe the law of stretched systems~\cite{Woods2006Joint}: ''every system is stretched to operate at its capacity; as soon as there is some improvement, for example in the form of new technology, it will be exploited to achieve a new intensity and tempo of activity.'' With the pattern and sliding autonomy methods, users had more tries and evaluated more options and tradeoffs. With the sliding autonomy method, users played with more time allocations and evaluated more paths suggested by path planning autonomy, which resulted in better quality paths at the cost of no performance increase in the secondary task.

%%===================================================
%\subsection{Fighting with Human Nature}
%
%It seems buried deeply in human nature that when a user performs an action, he/she wants immediate feedback so badly that when no such feedback is available, he/she cannot fight the urge to perform more actions thinking the additional actions would generate some feedback. To meet this demand, when we designed the sliding autonomy interface, we implemented two sliders where the second slider sets the step size value of the first slider. We had hoped that this would reduce the number of paths we had to pre-compute and make the user experience smoother by providing instant path feedback when they move the first slider. Observations from the user study show that this design actually negatively affected the user experience and increased user's cognitive workload. Which also means a better design with this element could potentially improve the user's performance and preference with the sliding autonomy method.
%
%Because when the value of the second slider is changed, the value of the first slider is also changed to reflect the smallest number that is a multiple of the selected step value. This behavior created multiple problems. First, some users quickly learned that changing the value of the second slider also changes time allocation to the path planning task, and started using this slider to set time allocation instead. This meant that more paths actually had to be pre-computed behind the scene, and in the user's eyes now the system was no longer providing instant feedback. So he/she began moving the slider randomly with the hope to generate some feedback, which meant more paths had to be pre-computed. A very bad cycle. Secondly, even though during training each user is told that there might be slight delay when they move the main slider in some cases, in the real exercises, they still wanted instant feedback. And when instant feedback was not available, they fell in the trap of operator-induced oscillation, and had to make several tries to set the value they desire. Fighting with the sliders required additional attention, so less attention were paid to monitor the group chat window. A ``please wait'' message would probably have less negative impact on the user's experience.
%
%When a human sees an ``obvious error'' in a path segment, the urge to correct is typically so strong that it draws all the attention to the quest, turning the path planning task into a fight with autonomy at the cost of increased cognitive workload. The ``obvious error'' could mean two different cases. In the first case, the ``error'' is indeed a bad move that can be easily modified in the user's mind to improve the path performance. In the second case, the ``error'' is actually not a bad move, only that the user cannot comprehend the reason behind the move, so there is still a strong desire to change it. However, because there is no direct way for the user to modify the path, the user can only change the path by moving the slider to set different time allocation, sometimes this ``error'' simply cannot be modified. The user wastes time trying, user's cognitive workload increases, and the user has a bad experience with the sliding autonomy method.
%
%There are probably more things than what we discussed here that could have improved the user experience and improve the user's performance on both the primary task of path planning and the secondary task of answering questions in the group chat window. We just want to emphasize that even with these negative impacts, the sliding autonomy method still performed significantly better than the other two methods and autonomy working alone without increasing the user's mental workload.

%=================================================================================	
\section{Conclusions and Future Work} 
\label{sec:Conclusions6}

In this paper we propose a new autonomy management approach, sliding autonomy, which lets the user influence the behavior of the autonomous system along three new dimensions: information representation, spatial constraints, and temporal constraints. We extend the autonomy design guidelines in our prior work by adding a new row for intelligence of collaborative agents (human-autonomy team), and explain how the three new dimensions fit into the guidelines when we apply the proposed approach to the task of UAV (Unmanned Aerial Vehicle) path planning to support Wilderness Search and Rescue (WiSAR). We present interface designs that let the user allocate degrees of authority and flexibility to the robot's algorithms through interactivities along these new dimensions. Experiment results from a user study validate our hypotheses and show that the sliding autonomy method performs significantly better than either the manual or pattern path planning method without increasing the user's mental workload, and the human-autonomy team outperforms either human or autonomy working alone.

Possible future work include evaluating the sliding autonomy approach in a long-term study and see how the user's trust can be calibrated. More complicated WiSAR scenarios can be tested and see how that affects the human-autonomy interaction and the performance of the human-autonomy team. Another user study can evaluate how well the human-autonomy team can work with outdated information representation using the sliding autonomy approach. It would also be interesting to investigate the human-autonomy interaction experience when the ability to modify information representation is added to the tool.

%=================================================================================	
\section*{Acknowledgments}

This work was partially supported by 
the National Science Foundation 
%\_\_\_\_\
under grant number 
0534736 and \_\_\_\_\_, 
%\_\_\_\_\_
and under grant number \_\_\_\_\_ from
the Army Research Laboratory.
%\_\_\_\_\.
Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsoring organizations.

\bibliography{LannyDissertation}

\hrule
\vspace*{.1in}
Authors' names and contact information: 

Lanny Lin, Brigham Young University, Provo, UT, USA.  Email: lanny@lannyland.com.  

Michael A. Goodrich, Brigham Young University, Provo, UT, USA.  Email: mike@cs.byu.edu.

Spencer Clark, Brigham Young University, Provo, UT, USA.  Email: spengy@gmail.com.

\end{document}

