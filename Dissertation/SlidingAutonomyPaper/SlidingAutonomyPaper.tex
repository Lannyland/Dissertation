\documentclass[lettersize, apacite, twoside, HRI]{apa_HRI}
% Required package for HRI journal format
\usepackage{times}
\usepackage{apacite}

% some very useful LaTeX packages include:
\usepackage{graphicx}  % Written by David Carlisle and Sebastian Rahtz
\usepackage{subfigure} % Written by Steven Douglas Cochran
                        % This package makes it easy to put subfigures
                        % in your figures. i.e., "figure 1a and 1b"
                        % Docs are in "Using Imported Graphics in LaTeX2e"
                        % by Keith Reckdahl which also documents the graphicx
                        % package (see above). subfigure.sty is already
                        % installed on most LaTeX systems. The latest version
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/subfigure/
                      
% The following are options that can be used in apa.cls but that are not used in apa_HRI
%\journal{Do not include -- hard coded}
%\volume{Volume 1, Number 3, pp. 1-16}
%\copnum{Do not include -- hard coded}
%\ccoppy{Do not include -- hardcoded}
%\ThreeLevelHeading  % HRI has a required heading style, and the HRI option overrides any of the apa.cls heading style commands

% The following are required options for the HRI journal format
\rightheader{Sliding Autonomy for UAV Path Planning}   % This should be the title, or a shortened version of the title if your title is long.
% \shorttitle{Beyond Fan-Out}    % Not used in HRI journal mode
\leftheader{Lin et al.}	  % For one or two authors, include both authors last names.  For three or more, use first author's last name et al.

% REQUIRED: paper title
\title{Sliding Autonomy for UAV Path Planning: Adding New Dimensions to Autonomy Management}

% REQUIRED: Author names and affiliations
% Note that authors from up to six affiliations can be added.  Beyond that, you are on your own.
% Group authors from the same affiliation together -- see example for two authors
%\author{Sole Author}
%\affiliation{Author Affiliation}
\author{Lanny~Lin, Michael~A.~Goodrich
, Spencer~Clark
}
\affiliation{Computer Science Department, Brigham Young University}
%\threeauthors{First Author}{Second Author}{Third Author} 
%\threeaffiliations{First Affiliation}{Second Affiliation}{Some Important Place}
%\fourauthors{First Author}{Second Author}{Third Author}{Fourth Author}
%\fouraffiliations{First Affiliation}{Second Affiliation}{Third Affiliation}{Fourth Affiliation}
%\fiveauthors{First Author}{Second Author}{Third Author}{Fourth Author}{Fifth Author}
%\fiveaffiliations{First Affiliation}{Second Affiliation}{Third Affiliation}{Fourth Affiliation}{Fifth Affiliation}
%\sixauthors{First Author}{Second Author}{Third Author}{Fourth Author}{Fifth Author}{Sixth Author}
%\sixaffiliations{First Affiliation}{Second Affiliation}{Third Affiliation}{Fourth Affiliation}{Fifth Affiliation}{Sixth Affiliation}

% REQUIRED: author addresses and email addresses
% Only the company/university/lab should be listed in affiliations above.
% The full address and email addresses will be included in a footnote.
% An address and email are only required for the corresponding author, but others may be included.

% REQUIRED: abstract
\abstract{
Increased use of autonomy also increases human-autonomy interaction and the need for humans to manage autonomy. We propose a new variation of the concept of sliding autonomy that is useful for planning problems over a spatial region. In this sliding autonomy approach, the user can influence the behavior of the autonomous system via three categories of input: information, spatial constraints, and temporal constraints. We present a set of user interface designs to implement sliding autonomy for UAV (Unmanned Aerial Vehicle) path planning to support Wilderness Search and Rescue (WiSAR). Interactivities along these new dimensions allow the user to allocate degrees of authority and flexibility to the robot's algorithms. We analyze how this approach fits in the integration challenge guidelines we identified in our prior work and evaluate the usefulness of the approach against manual and simple pattern path planning methods with a user study. Results show that the sliding autonomy approach performs significantly better than the other two methods without increasing the users' mental workload, and the performance of the human-autonomy team outperforms either human or autonomy working alone. We also discuss some interesting observations from the user study.
}

% REQUIRED: keywords
\keywords{human-robot interaction, unmanned aerial vehicles, path planning, navigation, adjustable autonomy, supervisory control, sliding autonomy}

% OPTIONAL: at submission time, you may include the following terms that may be useful for reviewers.
% These should be commented out in the final manuscript submrission. 
%\field{Technical, behavioral, design, or other}
%\contribution{article, short report, perspective, other (state)}
%\COI{Conflict of interest?  state}
%\uniqueness{State here (see CFP for required statement)}

%\acknowledgements{}

%% numbers option provides compact numerical references in the text. 
%\usepackage[sort,compress,numbers]{natbib}
%\usepackage{multicol}
%\usepackage[bookmarks=true]{hyperref}
%\usepackage{graphicx}
%\usepackage{amsmath}
%\usepackage{array}
%\usepackage{algpseudocode}
% 
%% \usepackage{caption}
%\usepackage{indentfirst}
%\usepackage{amsmath}
%\usepackage{multirow}
%\usepackage{array}
%\usepackage{algpseudocode}
%\usepackage{epstopdf}
%\newcommand{\rr}{\raggedright}
%\newcommand{\tn}{\tabularnewline}
%\newcommand{\shortcite}[1]{\cite{#1}}
%\newcommand{\degree}{\ensuremath{^\circ}}

% make the title area
\begin{document}
\maketitle

%=================================================================================
\section{Introduction}
\label{sec:Introduction6}

% First talk about need for autonomy management, especially for domain experts who don't know or care about how autonomy works
With the rapid advancement in technology, people are seeing increased use of autonomy to augment human abilities and support human decision-making in many application domains (e.g.,~\cite{Chun2010Limousine,Casper2003Human,Lin2010Supporting,Robins2009From}). At the same time, increased use of autonomy also means increased human-autonomy interaction and increased need for humans to manage autonomy~\cite{Bainbridge1983Ironies}. Even for so-called fully autonomous systems, human input can potentially improve the system's performance and safety~\cite{Bradshaw2013Seven}. The humans in such interactions manage autonomy because ``only people are held responsible for consequences (that is, only people can act as problem holders) and only people decide on how authority is delegated to automata''~\cite{Woods2006Joint}.

When humans manage autonomous systems, their managerial responsibilities often include monitoring the safety of the autonomous system, supervising autonomy to achieve acceptable performance, and making sure autonomy is working toward the collective goal of the overall system. In many emerging domains, the human operators are domain experts who can use domain-specific knowledge to assist the autonomous system when it deals with changing environments, uncertainty, and case-specific scenarios. Therefore, it is necessary to design tools and interfaces that enable human users to manage the autonomous behaviors of the system efficiently and effectively; such tools can improve task performance and the experience of the human operator in human-autonomy interaction. Wilderness Search and Rescue (WiSAR) is one such domain that could benefit from autonomy management tools when a mini-UAV (Unmanned Aerial Vehicle) is used in search.

% Discuss what application domain we apply this to, and the benefits.
Camera-equipped mini-UAVs can be useful tools in WiSAR operations by providing aerial imagery of a search area with the benefits of quick coverage of large areas, access to hard-to-reach areas, and lower cost than manned aircraft~\cite{Murphy2008Cooperative, Goodrich2008Supporting}. In fact Canadian mounties claim that they have successfully saved a person with a police drone in a recent rescue mission\footnote{http://www.theverge.com/2013/5/10/4318770/canada-draganflyer-drone-claims-first-life-saved-search-rescue}. UAV path planning is an important task because a good flight path can increase the probability of finding a missing person by making efficient use of the limited flying time. Various algorithms have been developed to support UAV path planning autonomy (e.g.,~\cite{Bourgault2003Coordinated, Lin2009UAV, Lin2014Hierarchical}), but the question remains how best to incorporate searcher expertise in such a way that the UAV path planning is as efficient and effective as possible.  The key constraint that we impose on this question is that we want to do this without requiring the searcher to understand how the autonomy works ``behind the scene.''
 
% Then we describe our approach.
We propose a new autonomy management approach where the user can influence the behavior of an autonomous system along three new dimensions: 1) \textbf{Information Representation}: information used by the robot is presented to the human in a human-readable form, and the human directly modifies this information to effect change in robot behavior; 2) \textbf{Spatial Constraints}: a human can add constraints or priorities to different spatial regions, thereby affecting how the robot plans and performs its task; and 3) \textbf{Temporal Constraints}: A human can impose time limits for a subtask or impose ordering constraints on a subtask. We refer to this approach as \textit{Sliding Autonomy} because, properly designed, it can allocate degrees of authority and flexibility to the robot's algorithms by adding or removing constraints, or by shaping input information. Indeed, we will explicitly use a \textbf{slider} as one GUI tool for managing UAV path planning.

As the human modifies information, adds piorities, or changes constraints, the sliding autonomy tool shows immediately how those changes influence the UAV's plan. This instant feedback provides the searcher the ability to perform ``what-if'' analysis and see the causal effect between his/her action and changes in autonomous behavior. This allows an interactive approach where autonomous algorithms perform tasks that they are good at and humans do tasks that they are good at, but in a collaborative and interactive way that avoids the pitfalls of simple task allocation~\cite{Sheridan1992Telerobotics,Bradshaw2013Seven}. Properly done, the human-robot team should perform better than a human or robot working alone. 

% Briefly talk about existing approaches and what we propose, and why different.
Many approaches to autonomy management already exist and are called many different things, such as \textit{supervisory control}~\cite{Sheridan1992Telerobotics}, \textit{mixed-initiative}~\cite{Hearst1999Mixed}, \textit{collaborative control}~\cite{Fong1999Collaborative}, \textit{adjustable autonomy}~\cite{Dorais1998AdjustableAutonomy,Dorais2001Designing} (also referred to as \textit{sliding autonomy}~\cite{Dias2008SlidingAutonomy} or \textit{adaptive automation}~\cite{Rouse1988Adaptive,Kaber2001Design}). The approach we propose falls under the category of \textit{adjustable autonomy}. The three dimensions we identified are in addition to dimensions of \textit{adjustable autonomy} identified by Bradshaw et al.\, so we design tools and algorithms that operate in a particular place in Bradshaw's taxonomy~\cite{Bradshaw2004Dimensions}.

% Talk about that we extended our guidelines
In our previous work~\cite{Lin2010Supporting} we identified key elements of autonomy integration challenges along two dimensions: \textit{attributes of an intelligent system} (capability, information management, performance evaluation) and \textit{organizational scale} (individual versus group), which can serve as guidelines in designing autonomous components and autonomy management tools. In this paper we extend the guidelines to include attributes needed when a human and autonomy work collaboratively and analyze how our proposed sliding autonomy approach fits in the guidelines. By applying sliding autonomy to the UAV path planning task, we argue that this approach:
\begin{itemize}
\item enables the domain expert user to incorporate information only available to or understandable by the expert;
\item is easy to understand without knowing how autonomy works behind the scene;
\item lets the human do what the human is good at (planning strategically and balancing performance tradeoffs) and autonomy do what autonomy is good at (planning tactically), resulting in better performance than human or autonomy working alone;
\item enables the user to align the task goal (find the path that maximizes probability collected along the path) with the system goal (finding the missing person quickly) when the user has more information or more up-to-date information than autonomy; and
\item improves human's experience during the human-autonomy interaction.
\end{itemize}

% We did user study to evaluate the approach. What are the results.
To evaluate the usefulness of the proposed approach, we performed a user study and compared the sliding autonomy method against two other planning methods (manual and simple pattern path planning) in two WiSAR scenarios (a synthetic scenario and a real scenario). We measured each user's performance with each method and also the user's performance on a secondary task (answer questions in a group chat window). Experiment results show that the sliding autonomy method performed significantly better than the manual or simple pattern planning methods with no increased mental workload. The human-autonomy team also performed better than the human or autonomy working alone.

% What does each section talk about?
In Section~\ref{sec:dimensions} we explain how the proposed approach fits into the extended autonomy design guidelines and describe how a user can manage autonomy along each of the three new dimensions in the context of UAV path planning. Section~\ref{sec:RelatedWork6} covers related work in literature. Section~\ref{sec:Hypotheses} lists our hypotheses followed by user study design in Section~\ref{sec:Design}. Then we present experiment results in Section~\ref{sec:Results} and discuss our observations in Section~\ref{sec:Discussion}. In Section~\ref{sec:Conclusions6} we conclude the paper and list possible future work.

%=================================================================================
\section{Autonomy Design Guidelines and New Dimensions}
\label{sec:dimensions}

%===================================================
\subsection{Autonomy Design Guidelines}

In our previous work~\cite{Lin2010Supporting} we organized the challenges of autonomy and management tool design along two dimensions: \textit{attributes of an intelligent system} (capability, information management, performance evaluation) and \textit{organizational scale} (individual versus group), which can serve as guidelines in designing autonomous components and autonomy management tools. In our definition we treat a system of human(s) and algorithms working together as an intelligent system. In this paper we extend this table by adding a row in the middle describing what attributes are needed when multiple agents work collaboratively (see Figure~\ref{IChallenges}). A human-autonomy team working on the same task falls within this category. 

Give one or two sentences that define how we use the word "intelligent" in this paper, including the fact that we are treating a system of human(s) and algorithms as an intelligent system a la the integrated intelligence paper.


\begin{figure}
\centering
\includegraphics[width=5.5in]{IntegrationChallenges.JPG}
\caption{Autonomy integration challenges defined along two dimensions. Horizontal dimension: attributes of intelligence. Vertical dimension: organizational scale.}
\label{IChallenges}
\end{figure}

As an individual tool, each autonomous component needs to be able to perform a task (\textbf{Autonomy}); the operator can match the component's capability to a specific task according to the information available to the operator, which requires that autonomy can be interrupted, paused, aborted, and resumed (\textbf{Flexibility}); the performance is evaluated by how well the component accomplishes the task goal in the absence of human input.

When a human-autonomy team works on the same task collaboratively, the autonomous component needs to provide interfaces so the human can interactively influence the autonomous behavior (\textbf{Interactivity}); the human should be able to manage how autonomy works in order to jointly find a solution by utilizing information only available to the human and/or feed information to autonomy in a representation that the autonomy can understand (\textbf{Manageability}); and when performance is evaluated, the human operator can judge whether the individual goal aligns with the collective goal of the system. 

As part of a larger distributed system, each component and collaborative subsystem needs to be modular (\textbf{Modularity}), so they can be mixed and matched to support different user roles; information from various sources need to be combined and presented to one or multiple users (\textbf{Fusion}); and performance of the complete human-machine system needs to be evaluated as a whole. 

This paper focuses on the middle row of the guidelines: intelligence of collaborative agents (human-autonomy team). The three dimensions we propose are ways path planning autonomy can be managed, and our path planner interface is designed to accept human input along the three dimensions to provide interactivity. The human can also incorporate information from various sources and influence the behavior of path planning autonomy by allocating degrees of authority and flexibility, making sure the task goal aligns with the ultimate goal of finding the missing person quickly.

%===================================================
\subsection{Information Representation Dimension}

The right information representation is task specific. Many path planning algorithms use a \textit{probability distribution map} that encodes the likely location of a target; for WiSAR, instead of a target we are interested in the probable location of the missing person, so the path planning algorithm should be able to account for this distribution. Adopting a Bayesian perspective, this distribution represents the prior probability of the location of the missing person.

Completing the Bayesian approach requires a likelihood that encodes the probability of seeing the missing person given that the person is located in a particular location.  We represent the likelihood using what we call a \textit{task-difficulty map}, which is a spatial representation showing (one minus) the sensor detection probability in different parts of the search region. For example, the prior probability of the missing person being near the last known position (LKP) is normally high (high prior probability); and the probability of detecting the missing person in a dense vegetation area using an airborne camera is normally low (high task difficulty). The objective of path planning is to find a path that maximize the cumulative posterior detection probability of the missing person given a fixed flying time. 

Since WiSAR experts use maps and probabilities in much of their work, we argue that presenting information about prior probabilities and likelihoods in a map form to the human allows the human to influence path planning autonomy by ``shaping'' these two maps. Prior work has demonstrated that these two maps can be systematically generated based on terrain features and vegetation data~\cite{Lin2010Bayesian, Lin2014Hierarchical}. However, the searcher likely wants to include his/her domain expertise (past experience, knowledge of the search region, etc.) and additional information (maybe new evidence found during the search) in the planning. These types of information are not directly understandable by autonomous algorithms, but the searcher can incorporate them into the probability distribution map and the task-difficulty map using map editing tools\footnote{Such as these tools at http://tech.lannyland.com/demos.html.} and thereby influence the behavior of path planning autonomy.

Marking an area with high probability, the searcher indirectly tells the UAV to treat the area with high priority; marking an area with high task-difficulty, the UAV might make multiple passes over the area to search more thoroughly. The 3D surface in Figure~\ref{dimensions6} shows an example probability distribution map where hills (red) indicate high probability and the flat area (blue) indicates low probability.

\begin{figure}
\centering
\includegraphics[width=3.5in]{Dimensions.JPG}
\caption{A screen capture of the sliding autonomy tool showing a 20-minute path segment. The 3D surface shows the probability distribution map. The UAV icon in the middle indicates the start point of the path segment and the sphere on the right indicates the end point.}
\label{dimensions6}
\end{figure}

We hypothesize that by allowing a human to directly manage this type of information, the human can quickly figure out how his or her actions will affect the behavior of autonomy, even though he/she has no idea about how autonomy works behind the scene. We have designed a user interface that allows a human to do this and have conducted subjective evaluations of the interface, but statistical validation of this hypothesis using a careful user study is left to future work.

%===================================================
\subsection{Spatial Constraints Dimension}

The searcher should also be able to influence the behavior of path planning autonomy by setting/changing spatial constraints. Spatial constraints can be in the forms of start/end points of the path segment or task-specific zones.

Setting an end point in an area is a way for the searcher to indirectly tell path planning autonomy that the area should have higher priority than other areas. For example, if a piece of clothing is found by the ground team, the searcher can force the path planning autonomy to go visit that area by setting an end point there. Because the UAV must allocate part of the fix-length flight time to reach this specified area, some areas that had good payoffs before this constraint is set can become relatively costly and, therefore, no longer attractive to path planning autonomy. Importantly, since we have assumed a fixed flight duration, setting an endpoint not only directly causes the UAV to focus search effort around that location but also indirectly causes the UAV to avoid other areas because the budget does not allow them to be searched well. In Figure~\ref{dimensions6}, the UAV icon in the middle indicates the start point of the path segment and the sphere on the right side indicates the desired end point. 

In the GUI, the end point can be dragged around the search region and path planning autonomy suggests different paths accordingly. This capability enables the user to adjust how much freedom is granted to autonomy. When the end point is close to the start point, autonomy has greater authority and flexibility in creating paths. If the end point is far from the start point, authority and flexibility for autonomy is reduced because a major part of path planning is simply moving the UAV toward the end point with the shortest path.

A task-specific zone can be a \textit{no-fly zone}, a \textit{coverage zone}, or a \textit{sampling zone}. A no-fly zone is a pretty straight-forward way to restrict the UAV from visiting certain areas~\cite{Clark2013Hierarchical,Jorris2009Three}. The decision might be for safety reasons or part of the searcher's strategic planning depending on resource allocation. A coverage zone requires the UAV to fully cover the area~\cite{Lin2009UAV}; a sampling zone only asks the UAV to collect a few sensor samples from the zone, so the visit can be very brief~\cite{Clark2013Hierarchical}. A task-specific zone can be dragged around and the searcher can also change the shape and/or size of the zone to influence the path generated by autonomy.

The interactive ability to move the end point around (or changing the shape of the no-fly zone) and see immediately how the change would affect the UAV path recommended by path planning autonomy gives the user the power to perform ``what-if'' analysis. It also allows the user to see the causal effect between his/her action and changes in autonomous behavior.

Spatial constraints are easy to understand, so the searcher knows how these constraints will affect the behavior of path planning autonomy. By managing autonomy along this dimension, the searcher has another way to incorporate additional information to the path planning task, improve task performance, and align the task goal with the overall goal of finding the missing person quickly. 

In our user study we fixed the start point of the path to the center of the map because that was the last know position of the missing person. The searcher can set the end point for the current path segment anywhere on the map, and this end point automatically becomes the start point for the next path segment. We disabled the ability to move an end point once a path segment is planned to reduce computation, but we let users reset an entire plan, effectually allowing them to try different combinations of starting and ending path segments. Task-specific, sampling, and explicit no-fly zones were evaluated in a separate user study~\cite{Clark2013Hierarchical}.

%===================================================
\subsection{Temporal Constraints Dimension}

In the UAV path planning problem, temporal constraints include a \textit{time limit} for a subtask (path segment), \textit{subtask ordering}, and \textit{valid time window}.

With the time limit constraint, the searcher can decide how much flight time to allocate to a path segment out of the total flight time. This enables the searcher to break the path planning task into multiple subtasks and then plan each path segment separately. In our interface design we let the searcher control time allocation to autonomy using a slider, and as the searcher moves the slider, the path planning autonomy shows how the suggested path segment changes respectively. Similar to the spatial constraints, this instant feedback enables ``what-if'' analysis and provides instant feedback on the causal effect between searcher action and changes in autonomous behavior.

For example, for a 60-minute total flight with an end point set to the probability hill on the right (Figure~\ref{dimensions6}), the searcher can move the slider to set time limits and see immediately what path segment the autonomy would suggest. The path segment shown is when 20 minutes are allocated out of a total flight time of 60 minutes. If the searcher is happy with the suggestion, he or she approves the path segment. The UAV moves to the end point in the path planner and ``vacuums up'' the probability along the path (how much can be vacuumed up is determined by the task-difficulty map). Then the searcher works with the autonomy to plan the path for the remaining 40 minutes. The two (or more) path segments are joined to form the final path.

A subtask ordering constraint adds temporal dependency to the subtasks (e.g., the sampling task must be flown before the coverage task). This type of constraint lets the searcher directly specify priorities in different search areas. 

A valid time window constraint specifies a time interval during which a subtask must be completed.  This is less restrictive than giving a time limit constraint because the specified task can be accomplished at anytime during the window, and more restrictive than an ordering constraint because the task must be accomplished before a deadline and after a start time. 

By managing autonomy along the temporal constraint dimension, the searcher can break the path planning task into subtasks and incorporate additional information into the path planning task. The user study described in this paper includes the time limit constraint. Subtask ordering and valid time window constraints are evaluated in a separate user study~\cite{Clark2013Hierarchical}).

In the example shown in Figure~\ref{dimensions6}, the combination of the three dimensions resulted in a path that covers the middle area well before moving right. If no end point is set, autonomy might decide to move left, instead. Less time allocation forces autonomy to focus more on the local area; more time allocation increase authority and flexibility, so autonomy has more freedom on deciding what areas to cover. Instant feedback on path changes when constraints change lets the searcher interactively review multiple options and select the path segment that fits best with his/her strategic planning. This design enables human to plan more strategically (prioritizing areas in the entire search region) while autonomy works more tactically (covering the current search area well), using strengths of each when they work collaboratively. Ideally such a human-autonomy team should work better than either human or autonomy working alone.

%=================================================================================
\section{Related Work}
\label{sec:RelatedWork6}

Many approaches on how human-autonomy team can work together have been proposed in the literature. Drucker defines automation as a ``concept of the organization of work~\cite{Drucker2006Practice}.'' Goodrich and Schultz define the HRI problem as ``understanding and shaping the interactions between one or more humans and one or more robots''~\cite{Goodrich2007HRISurvey}. They also specified robot-assisted search and rescue as a key area for HRI research. In their 1978 seminal paper, Sheridan and Verplank propose the idea of a \textit{level of autonomy} spectrum, with full teleoperation at one end and full autonomy at the other~\cite{Sheridan1978Human}. In the middle, the robot could suggest actions to humans or make decisions before informing humans. Parasuraman et al.\ extended this one-dimensional spectrum to four different broad functions: information acquisition, analysis, decision selection, and action implementation~\cite{Parasuraman2000Model}. Sheridan proposes \textit{supervisory control}, in which a human divides the task into a sequence of subtasks that the robot is capable of performing, and the human then provides guidance when the autonomous system cannot solve a problem on its own~\cite{Sheridan1992Telerobotics}. In contrast to the top-down philosophy of supervisory control, a \textit{mixed-initiative} approach advocates the idea of dynamically shifting tasks when necessary~\cite{Hearst1999Mixed}. \textit{Collaborative control}, which can be thought of as an instance of mixed-initiative interaction, is a robot-centric model; instead of the human always being in-charge, the robot is treated as a peer and can make requests to humans through dialogs~\cite{Fong1999Collaborative}. \textit{Adjustable autonomy}~\cite{Dorais2001Designing} (also referred to as \textit{sliding autonomy}~\cite{Dias2008SlidingAutonomy} or \textit{adaptive automation}~\cite{Rouse1988Adaptive}) is another type of mixed-initiative interaction, one that enables the human-automation team to dynamically and adaptively allocate functions and tasks among team members. 

Many implementations of different flavors of adjustable autonomy exist. Dorais et al.\ discuss a framework for human-centered autonomous systems for a manned Mars mission~\cite{Dorais1998AdjustableAutonomy}. The system enables users to interact with these systems at an appropriate level of control but minimize the necessity for such interaction. Bradshaw et al.\ discuss principles and pitfalls of adjustable autonomy and human-centered teamwork, and then present study results on so-called ``work practice modeling'' and human-agent collaboration in space applications~\cite{Bradshaw2003AdjustableAutonomy}. Kaber et al.\ describe an experiment simulating an air traffic control task where manual control was compared to Adaptive Automation (AA)~\cite{Kaber2005Adaptive}. Results suggest that humans perform better with AA applied to sensory and psychomotor information-processing functions than with AA applied to cognitive functions; these results also suggest that AA is superior to completely manual control. Brookshire et al.\ present preliminary results for applying sliding autonomy to a team of robots performing coordinated assembling work to help the system recover from unexpected errors and to thereby increase system efficiency~\cite{Brookshire2004Preliminary}. Dias et al.\ identified six key capabilities that are essential for overcoming challenges in enabling sliding autonomy in peer-to-peer human-robot teams~\cite{Dias2008SlidingAutonomy}. Bradshaw et al.\ propose two dimensions of Adjustable Autonomy (descriptive and prescriptive) to address the two senses of autonomy (self-sufficiency and self-directedness) and discuss how permissions, obligations, possibilities, and capabilities can be adjusted~\cite{Bradshaw2004Dimensions}. Bradshaw et al.\ also summarized some widespread misconceptions on autonomy and listed seven deadly myths of ``autonomous systems''~\cite{Bradshaw2013Seven}.

The human is an integral part of the human-autonomy team. When working with autonomy, the human often takes on the supervisor role. Bainbridge points out that automation requires the human operator to take additional management responsibilities~\cite{Bainbridge1983Ironies}, and Sartar identified two automation management policies: \textit{management by consent} and \textit{management by exception}, defining whether the human always retain authority or can the system take initiative~\cite{Sarter1998Making}. For complex automation, the human tends to rely on his/her \textit{mental models}~\cite{Norman1983Some} to manage the system. 

Searchers working together with a UAV is an example of a human-autonomy team. UAV technology has emerged as a promising tool in supporting WiSAR~\cite{Murphy2008Cooperative,Bourgault2003Coordinated}. The goal of our research is to support fielded missions in the spirit of Murphy's work~\cite{Casper2003Human}. Many path planning algorithms in the literature address obstacle avoidance while planning a path to reach a destination using A*~\cite{Quigley2005Towards}, LRTA*~\cite{Howlett2006Learning}, D*~\cite{Stentz1997Optimal}, Voroni diagrams~\cite{Bortoff2000Path,Beard2005Autonomous}, or probability roadmaps and rapidly-exploring random tree (RRTs)~\cite{Pettersson2006Probabilistic}. 
%Hierarchical heuristics approaches were also developed, such as Hierarchical A* (HA*) by Holte et al.\ ~\cite{Holte1996Hierarchical}, hierarchical task-based real-time path planning by Naveed et al.\ ~\cite{Meuleau2007Hierarchical}, and Hierarchical-AO* (HiAO*) by Meuleau and Brafman~\cite{Naveed2010Hierarchical}. 
Bourgault et al.\ \cite{Bourgault2004Coordinated,Bourgault2006Optimal} describe how to use a Bayesian model to create paths for a single UAV or multiple coordinated UAVs to maximize the amount of probability accumulated by the UAV sensors. The algorithms we used in this paper are algorithms designed from our previous work~\cite{Lin2009UAV,Lin2014Hierarchical} using techniques such as global warming technique, convolution, Gaussian mixture models, and Evolutionary Algorithm.

%=================================================================================	
\section{Hypotheses} 
\label{sec:Hypotheses}

We performed a user study to evaluate the usefulness of the sliding autonomy approach. More specifically we verify the following hypotheses:

H1: The sliding autonomy method performs better than either either a manual path planning method and a semi-autonomous path planning method that uses standard search patterns to cover an area.

H2: The sliding autonomy method performs better than autonomy working alone.

H3: The sliding autonomy method does not increase the mental workload of the operator when compared against the manual and pattern methods.

%=================================================================================	
\section{User Study Design} 
\label{sec:Design}

\begin{figure}
\centering
\includegraphics[width=3.5in]{UserStudy.JPG}
\caption{Top: User study simulation interface with the sliding autonomy method showing the probability distribution map for scenario 1. Middle left: Probability distribution map for scenario 2. Middle Right: Task-difficulty map for scenario 2. Bottom: The three patterns available to user with the pattern planning method, spiral, lawnmower, and line.}
\label{UserStudy}
\end{figure}

We performed a 2$\times$3 within-subject design with 2 scenarios (easy vs. difficult) and 3 planning methods (manual, pattern, and sliding autonomy). All participants completed all 6 exercises. The order of the scenarios and planning methods was counterbalanced to reduce learning effect. We recruited a total of 26 college students (14 males and 12 females) between the age of 19 and 30 (average 22.89). 

After the demographic survey, each participant completed four 5-minute long non-skippable training sessions (one for each planning method with no task-difficulty map, and one for the manual method with a task-difficulty map) and then completed the 6 exercises. Each participant had up to 5 minutes for each exercise. Once the participant was happy with the path generated, he/she could finish the exercise early. We chose this design because we do not want the user to put all effort into completing the secondary task once he/she considers the primary task completed, which would skew the measurements on secondary task performance. At the end of each exercise, the participant completed a partial NASA TLX survey. Then at the very end of the user study, the participant filled out a survey describing his/her subjective preference with the three planning methods.

%===================================================
\subsection{Simulation Environment}

The user study was conducted in a 3D simulation environment (see Figure~\ref{UserStudy}) where both the probability distribution map and the task-difficulty map were displayed as 3D surfaces with a color map (red means high and blue means low). The user could switch between the two maps at any time and rotate/pan/zoom a map at will. The UAV was a hexacopter capable of flying in all directions or hovering in the same spot. The UAV start point is set at the center of the search region because that was the last point known (LPK) for the missing person.

With the \textbf{manual} planning method, the user flew the UAV with the arrow keys in a sped up fashion (i.e., enabling the user to cover ground faster than the UAV could cover it in real flight). The user could switch between two flying modes (turn and strafe) and four camera views (global, behind, bird's eye, and free form). The user could also pause/resume the flight for the secondary task or better planning.

With the \textbf{pattern} planning method, the user chose from spiral, lawnmower, and line patterns (see Figure~\ref{UserStudy} bottom) and joined these patterns to form the final path. The end point of the previous path segment (LPK if at the very beginning) automatically became the start point of the current selected pattern. As the user moved the cursor around, the size of the pattern changed with the cursor position marking the end point of the pattern (The start/end points pair determined the radius of the spiral pattern, the diagonal of the rectangle for the lawnmower pattern, and the start/end points for the line pattern). Once the user was happy with the location, shape, and size of the pattern, he/she could approve the pattern with a left click. The user could also undo the last path segment (pattern) planned. This planning method was ``semi-autonomous'' because the patterns were generated automatically without manually setting waypoints.

With the \textbf{sliding autonomy} method (see Figure~\ref{UserStudy} top), the user could set an end point (optional), and then drag the left slider to change the amount of time allocated to autonomy. The path suggested by the autonomy changed as the slider moved. The slider's max value always reflected the remaining flight time (in minute). If the user were happy with the current path segment, he/she could approve it, the UAV then moved to the end of the path segment, and the process repeated until a path has been planned that accounts for all of the available flight duration. The path planning algorithm used was the LHC-GW-CONV algorithm~\cite{Lin2009UAV, Lin2014Hierarchical}, because it is the fastest algorithm out of all the algorithms we designed and produces satisfactory sub-optimal performance when compared to other state-of-the-art algorithms for the problem.

With all three planning methods, the user could choose to start over at any time during the exercise, and could restart as many times as exercise time allowed. We recorded the best path out of all tries.

%===================================================
\subsection{Scenarios}

The user study contained two WiSAR scenarios, a synthetic case (see Figure~\ref{UserStudy} top) with no task-difficulty map (assuming uniform detection probability), and a real WiSAR scenario (see Figure~\ref{UserStudy} middle) with a task-difficulty map, in which an elderly couple was reported missing near the Grayson Highlands State Park in Virginia~\cite{Koester2008Lost}\footnote{The probability distribution map used for this scenario (Figure~\ref{UserStudy} middle left) was generated using a Bayesian model~\cite{Lin2010Bayesian}. The map has been evaluated at George Mason University's MapScore web portal~\cite{Twardy2012MapScore} and performed better than most other models evaluated, scoring 0.8184 on a [-1,1] scale where the higher the score the better. http://sarbayes.org/projects/. The task-difficulty map (Figure~\ref{UserStudy} middle right) was generated using vegetation density data downloaded from the USGS web site and categorized into three difficulty levels (sparse, medium, and dense, with detection probability of 100\%, 66.67\%, and 33.33\% respectively).}.

Scenario 2 is clearly more complex than scenario 1 because the user also had to consider the different detection probability defined by the task-difficulty map. We refer to scenario 2 as the high information scenario and scenario 1 as the low information scenario. These two scenarios exhibited significantly different amounts of workload in a pilot study and gave us confidence that the results scale to different types of scenarios.

%===================================================
\subsection{Secondary Task}

In each exercise, each participant also performed a secondary task. This provided a second measure of mental workload. In a group chat window (see Figure~\ref{UserStudy} top) when the user's code name appeared, the user had to type answers to simple questions. Roughly every 3 seconds a message was sent to the chat window, and every 5th message asked the user a simple question (4 per minute). For the same scenario and the same planning method, all users received the same set of chat messages.

We chose to use a group chat window as the secondary task because this is typical in WiSAR operations. We also designed the chat messages to simulate a real WiSAR search and improve ecological validity. The user was asked to acknowledge connection and report path planning status periodically.

%===================================================
\subsection{Measures}

We used the following five measurements for the primary path planning task:

\begin{itemize}
\item \textbf{Percent score}: In each exercise, an exercise score was computed by summing the amount of probability collected by the UAV if it followed the path planned. The user's best score for each exercise (out of multiple tries) was normalized by dividing the best score from all users for the same scenario to compute the percent score. This way we could compare planning methods across scenarios.
\item \textbf{Time spent}: How much time was spent with each exercise.
\item \textbf{Try count}: How many times the user tried in each exercise. Note that because the manual planning method takes much longer to plan a path than the other two methods by design, this measurement is used mainly to compare between the pattern and sliding autonomy planning methods.
\item \textbf{Mouse clicks per try}: How many times the user left-clicked the mouse within a try. Again, this measurement is used to compare pattern and sliding autonomy planning methods because the manual planning method does not require a lot of mouse clicks by design.
\item \textbf{NASA-TLX raw score}: The sum of user subjective evaluation of cognitive workload in six dimensions normalized to a 100-point scale. 
\end{itemize}

The following two measurements were used for the secondary task:
\begin{itemize}
\item \textbf{Percent of questions missed}: What percentage of questions directed to the user were missed before the user completed the exercise. Here we did not measure the percent of questions answered correctly because all the questions are very simple and all users answered the questions correctly.
\item \textbf{Chat latency}: The number of seconds between the time a question was presented to the user and the time when the user answered the question.
\end{itemize}

%=================================================================================	
\section{Results and Analysis} 
\label{sec:Results}

We analyzed the user study data with a mixed measures analysis of variance (ANOVA) and report results in this section.

%===================================================
\subsection{Comparing Across Scenarios}

%During the user study, each participant worked through two WiSAR scenarios. In scenario 1 (low information) no task-difficulty map is used. In scenario 2 (high information) because partial detection is enforced, the amount of probability that can be collected (exercise score) in scenario 2 is much lower than in scenario 1. In order to show a fair comparison across scenarios, we use percent score instead, which compares the participant's score to the best performing participant's score in the same scenario.

Mouse clicks per try for the two scenarios are significantly different ($F[1,25]= 28.65, p<.0001$) indicating scenario 2 required participants to be more active than in scenario 1. This result supports observations in the pilot study that scenario 2 imposed higher workload on participants than scenario 1. Evaluating logs of user activity indicates that participants created more path segments (for pattern and sliding autonomy planning methods) in scenario 2 than scenario 1. 

NASA TLX scores are also significantly different ($F[1,25]= 31.35, p<.0001$) between the two scenarios. The average score difference is 9.98 (out of a total of 100 points), almost a full ``pip'' on the TLX survey, indicating that on average each participant felt his/her cognitive workload was much higher in the high information scenario.

The percent of questions missed is almost identical between scenarios (54.88\% and 54.90\%), and the chat latency is also very close (10.39 and 11.17 seconds). This shows that participants on average performed about the same with the secondary task across scenarios. No statistically significant differences were found across scenarios for percent score, time spent, and try count.

%===================================================
\subsection{Comparing Across Planning Methods}

For each scenario, three path planning methods were used (manual, pattern, and sliding autonomy). Table~\ref{AcrossMethods} lists comparison among these three methods. 

\begin{table}
\caption{Comparing across planning methods (SE stands for standard error)}
	\centering
		\begin{tabular}
			{|l|c|c|c|c|c|}
			\hline
			& M & P & SA & SE & Significance \\			
			\hline
			\% Score & 59.40 & 72.75 & 94.60 & 1.39 & $\boldsymbol{F[2,50]=223.03, p<.0001}$ \\
			Time spent & 243.35 & 240.02 & 228.37 & 12.06 & $F[2,50]=1.16, p=.32$ \\
			Try count & 1.75 & 3.56 & 3.31 & 0.43 & $F[2,50]=9.47, p=.0003$ \\
			Clicks/try & 13.01 & 35.64 & 25.58 & 2.90 & $\boldsymbol{F[2,50]=19.47, p<.0001}$ \\
			NASA TLX & 61.51 & 49.18 & 48.86 & 2.81 & $\boldsymbol{F[2,50]=14.15, p<.0001}$ \\
			\hline
			\% Q. missed & 52.94 & 56.69 & 55.04 & 5.17 & $F[2,50]=1.26, p=.29$ \\
			Chat latency & 10.39 & 11.17 & 10.92 & 0.65 & $F[2,50]=0.46, p=.63$ \\
			\hline			
			\multicolumn{6}{c}{}  % This is a patch to fix a bug in the table command.									
		\end{tabular}
\label{AcrossMethods}
\end{table}

Percent score differences are statistically significant ($F[2,50]= 223.03, p<.0001$) with sliding autonomy (94.60\%) performing better than pattern (72.75\%) and manual (59.40\%). As shown in Figure~\ref{PerformanceDifference}, this trend is also clear in both scenario 1 and 2 individually. Therefore, user study results support our first hypothesis: sliding autonomy method performs better than either the manual method or the pattern method. This holds for both high and low information scenarios, suggesting some robustness of the result across a range of scenarios.

\begin{figure}
\centering
\includegraphics[width=3.5in]{PerformanceDifference.JPG}
\caption{Performance differences for the three path planning methods.}
\label{PerformanceDifference}
\end{figure}

Statistically significant differences ($F[2,50]=19.47, p<.0001$) were also found in mouse clicks per try (starting over means having another try). The manual method uses arrow keys to fly the UAV around and only uses mouse clicks when switching camera modes or stop the timer in order to perform the secondary task. By design, this method does not use a lot of mouse clicks. Pattern and sliding autonomy methods both use mouse clicks for the actual path planning task, and the pattern method clearly generated more mouse clicks per try (35.64) than the sliding autonomy method (25.58). Two factors might have contributed to this difference: First, the pattern method allowed a participant to "undo" a path segment (in additional to reset and start over) whereas sliding autonomy did not allow this. Second, sliding autonomy allowed a participant to drag a slider, which produced different suggested paths; this accomplishes the same type of ``what if'' interaction as ``undo'' in the pattern method, but required many fewer mouse clicks.

It is informative to compare these interactive planning methods with a fully autonomous path. This is useful because, due to the computational complexity of the planning problem, only suboptimal solutions can be generated by the planning algorithms. Completely autonomous path planning (without human input) produces paths with a score of 96.13\% for scenario 1 and 78.33\% for scenario 2. It is instructive to compare these values to those produced by the different planning methods in the different scenarios (see Figure~\ref{PerformanceDifference}). This places the performance of full autonomy ahead of manual and pattern planning methods in both scenarios, but behind sliding autonomy in both scenarios. This indicates that the sliding autonomy approach outperforms both manual, pattern, and full autonomy approaches to the problem.

As shown in Table~\ref{CompareToFullAutonomy}, for scenario 1, no participants were able to outperform full autonomy using manual or pattern approaches, but 23 of 26 participants (88.46\%) were able to outperform full autonomy using sliding autonomy. For scenario 2, no participants were able to outperform full autonomy using manual control, but 5 of 26 participants (19.23\%) and 24 of 26 participants (92.31\%) were able to outperform full autonomy using pattern and sliding autonomy, respectively. Thus, results of the study support the second hypothesis: Sliding autonomy methods perform better than a fully autonomous approach given state-of-the-art planning algorithms for this problem.

The full autonomy we refer to here is the specific path planning algorithm we used in the user study (LHC-GW-CONV). In Section~\ref{Reliance}, we discuss how the sliding autonomy approach compares to other path planning algorithms.

\begin{table}
\caption{Percent of participants outperforming autonomy with each method}
%\small
	\centering
		\begin{tabular}
			{|l|c|c|c|}
			\hline
			 & Manual & Pattern & Sliding Autonomy \\
			\hline
			Scenario 1 (Low) & 0\% & 0\% & \textbf{88.46\%} \\
			\hline
			Scenario 2 (High) & 0\% & 19.23\% & \textbf{92.31\%} \\
			\hline			
			\multicolumn{4}{c}{}  % This is a patch to fix a bug in the table command.									
		\end{tabular}
%\vspace*{-2ex}
\label{CompareToFullAutonomy}
\end{table}

NASA TLX raw scores show significant differences ($F[2,50]=14.15, p<.0001$) among the three methods, with the manual method showing the highest cognitive mental workload (61.51), a full ``pip'' more than the other two methods on the TLX survey. The average score difference between the pattern method and the sliding autonomy method is not significantly different. Figure~\ref{NASATLX} shows the box plots of the NASA TLX scores for each scenario.

\begin{figure}
\centering
\includegraphics[width=3.5in]{NASATLXBoxPlot.JPG}
\caption{Box plots of the NASA TLX scores for each scenario.}
\label{NASATLX}
\end{figure}

For all three planning methods, participants performed about the same on the secondary task, as shown by percent of questions missed and chat latency in Table~\ref{AcrossMethods}. Combining this with percent score and NASA TLX we can conclude that sliding autonomy performed best without increasing participants' mental workload, which support our third hypothesis: Sliding autonomy method does not increase the mental workload of the operator when compared against manual and pattern methods.

%===================================================
\subsection{Additional Factors}

We also performed ANOVA analysis on some additional factors that might create differences: gender, experience in video games, order of the scenarios, and whether participants used full autonomy with the sliding autonomy method. No significant differences were found for these factors overall, across scenarios, or across methods. There is also no significant correlation (-0.23) between percent of questions missed in the secondary task and the NASA TLX raw scores.

%=================================================================================	
\section{Discussion} 
\label{sec:Discussion}

%===================================================
\subsection{Planning Methods Characteristics}

\noindent \textit{Manual Method}

With the manual method, the user uses arrow keys to move the UAV around to create a path, so by design the method is very intuitive, flexible, and requires more physical interactions (keyboard, not mouse clicks). But in order to plan a 60-minute path faster than real-time (participants had to accomplish this in 2 minutes), although we designed the experiment using input from a pilot study, ensuring that each participant could complete at least two attempts during the 5 minutes allocated, many participants reported that the arrow keys were too ``sensitive'' and recommended slowing down the UAV.

Because of the time pressure, when errors are made, in practice it is too costly to start over (we did not provide an undo function). Although it is possible to pause the simulation to allow for participants to plan, participants reported that they did not feel that they had the the luxury to do so. Naturally, when this continuous process is interrupted by the secondary task where the user has to pause planning and answer questions in the group chat window, user frustration is high. 

More physical work, higher frustration, and lower performance score are the main factors contributing to a much higher NASA TLX score for the manual method. During training, participants actually had one extra session with the manual method, but this method still performed the worst.

~\\ \noindent \textit{Pattern Method}

With the pattern method, the user joins a mixture of three patterns (spiral, lawnmower, and line) together to form the final path. This is more of an episodic process, so it is very easy to pause in the middle of the planning and shift attention to the secondary task. There is also less time pressure because the user can quickly plan for the remaining time with just one big spiral (or lawnmower) in one click. Therefore, the user has plenty of time for many tries with different strategies.

In the post user study survey, many participants commented that with the spiral and lawnmower pattern it is really easy to run out of time. They suggested adding the ability to allocate time to the patterns similar to the sliding autonomy method. This means that with this method, a user enjoys the systematic coverage of an area but has a hard time estimating how much time it takes the UAV to cover the area following the pattern. Several participants also suggested adding more patterns to the method. 

The pattern method is the only method that allows a participant to ``undo'' a plan. This ability impacted the number of mouse clicks per try and participants' preference over the three planning methods. Another interesting observation is that participants seemed to be overly optimistic about their performance using the pattern method. For example, although sliding autonomy created better paths than pattern in all scenarios for all participants, 46.15\% of participants (as measured in the NASA TLX with the performance dimension) and 26.92\% (as reported in the post study survey) reported that the pattern method created best paths.

~\\ \noindent \textit{Sliding Autonomy Method}

Similar to the pattern method, the sliding autonomy method is also episodic. Therefore, stopping in the middle of the planning to answer questions for the secondary task was easy. Since it only takes a few clicks to let autonomy plan path for the remaining time, there is not much time pressure and the user can have many tries. 

Because the user does not know how autonomy works behind the scene, many participants were surprised by the path recommended by autonomy, and feel that autonomy did not do what they wanted it to do. For example, when a user sets the end point in region A, autonomy might plan a path that spends most of time in a seemingly unrelated region B and only goes toward region A at the end of the path, because such a path is more efficient (scores higher). In such cases, the slider becomes the only tool that lets the user ``force'' autonomy to do what the user wants, and path planning turns into a fight between the human and autonomy. However, the instant feedback (displaying path and the predicted ``vacuuming effect'') does help the user figure out why autonomy would suggest something different, and some participants were glad that autonomy suggested better paths they had not considered. 

Most participants were generally happy with the path segment recommended by autonomy covering a local region, even when the region is in an irregular shape (not a circle or rectangle). Many participants also expressed that they did not have enough control over the path generation and recommended adding the ability to include constraints such as ``middle points'' where the path segment has to go through these middle points. In fact, such ``middle points'' can already be achieved with the current method by setting multiple endpoints, effectually creating a multi-segment approach. Several participants complained that this method does not have the undo function. With both the pattern and sliding autonomy methods, many participants expressed the desire to be able to modify the path after it is generated.

~\\ \noindent \textit{User Preferences}

In scenario 2 where a task-difficulty map was used, most participants switched between map views. The probability map used is similar to a unimodal distribution (see Figure~\ref{UserStudy} middle left). For the first part of the planning, they viewed the probability distribution map and ``covered'' the high mode. They then switched the view to the task-difficulty map for the remaining time, only occasionally switching back to the probability distribution map view. This pattern of behavior was seen in each of the three planning methods. Some participants suggested showing both maps side by side or have a way to combine the two maps into one. These ideas are worth exploring in future user studies.

In the post user study survey, the majority of the participants think manual is the easiest to learn (53.85\%), pattern is the easiest to use (57.69\%), and sliding autonomy performed the best (65.38\%). However, most participants preferred the pattern method (69.23\%) out of all three. We believe the inability to undo and operator-induced oscillation when moving the slider had negative impacts on participants' preference over the sliding autonomy method. This is relevant for the design of future sliding autonomy systems, suggesting that some combination of pattern-based planning and sliding autonomy, augmented with the ability to undo decisions and flexibly alter or constrain paths, will produce a high-performing GUI with high user acceptance.

%===================================================
\subsection{Reliance on Autonomy}
\label{Reliance}

\begin{figure}
\centering
\includegraphics[width=3.5in]{PerformanceMarkers.JPG}
\caption{Comparing sliding autonomy performance against various markers.}
\label{PerformanceMarkers}
\end{figure}

We have claimed that a human interacting with an autonomous algorithm via sliding autonomy outperforms full autonomy, but this claim naturally depends on the quality of the autonomous algorithm. The algorithm we used was selected from a comparison of various algorithms in our prior work~\cite{Lin2009UAV,Lin2014Hierarchical} because it worked in real-time and produced high quality paths, but there exist other algorithms that produce higher quality paths if we allow more time for path-planning. It is useful to compare performance of the sliding autonomy algorithm with these other algorithms.

As a basis for comparison, we consider an evolutionary algorithm  (EA) that takes the output of several real-time planning algorithms, including the one we used in the user study, as seeds for the evolutionary process. Thus, the EA approach takes high quality solutions and then adds further optimizations. As shown in Figure~\ref{PerformanceMarkers}, when such optimization is applied to scenario 1 and scenario 2, the optimization produces a path that is only slight worse than sliding autonomy for scenario 1 and a path that is much better than sliding autonomy in scenario 2. This suggests that better path planning might be more important than interactive path planning.

Because we are arguing that human plus autonomy is better than either alone, we explored how the number of human input can affect the output of the sliding autonomy approach. Results indicate that the sliding autonomy algorithm we used in the user study can generate high quality paths with only one point of human input (specifying an end point). We call this approach the \textit{autonomy+1} approach.

Using the best score out of 3 tries (roughly equal to the average number of tries in the user study), we computed the percent score for this autonomy+1 human input approach: 99.47\% for scenario 1 and 98.58\% for scenario 2. Using the EA and Autonomy+1 scores as additional markers, we plotted participants average performance in each scenario against these markers. Figure~\ref{PerformanceMarkers} shows the result.

First, sliding autonomy (human-autonomy team) outperformed nominal autonomy in both scenarios. Sliding autonomy also outperformed EA in scenario 1 (low information). In scenario 2, the performance of sliding autonomy is not very far from EA (5.36\%), and the difference is even smaller (1.85\%) when averaged over both scenarios. However, the most interesting observation is that autonomy+1 actually outperformed all others in both scenarios (99.47\% for scenario 1 and 98.58\% for scenario 2). Although a few participants did score higher than autonomy+1, the difference is less than 1.5\%. Table~\ref{CompareToMarkers} lists what percentage of participants outperformed full autonomy, EA, and autonomy+1.

\begin{table}
\caption{Percent of participants outperforming autonomy performance markers}
%\small
	\centering
		\begin{tabular}
			{|l|c|c|c|}
			\hline
			 & Autonomy & EA & Autonomy+1 \\
			\hline
			Scenario 1 (Low) & \textbf{88.46\%} & \textbf{88.46\%} & 7.69\% \\
			\hline
			Scenario 2 (High) & \textbf{92.31\%} & 26.92\% & 15.38\% \\
			\hline
			\multicolumn{4}{c}{}  % This is a patch to fix a bug in the table command.						
		\end{tabular}
\label{CompareToMarkers}
%\vspace*{-2ex}
\end{table}

What Figure~\ref{PerformanceMarkers} suggests is that with the sliding autonomy method, it does not need a lot of human input to perform really well. Instead of spending the effort creating many path segments and setting many end points, it may be more effective to search in the right region by setting just a few constraints. However, 88.68\% of the participants gave more than 1 input when they used sliding autonomy (81.13\% for 2 inputs and 69.81\% for 3 inputs). In the post user study survey, only 46.15\% of the participants acknowledged trying full autonomy with the sliding autonomy method, meaning that these participants did no specify any endpoints and simply relied on the autonomous path-planner to do all the planning. When using the sliding autonomy method, a good strategy is actually to start with full autonomy (as the worst scenario) and then see how additional human input can improve the path, but this leads to questions of over- and under-reliance on autonomy~\cite{Bradshaw2013Seven}.

%===================================================
\subsection{Why Human-Autonomy Team Performs Better?}

User study results show that the human-autonomy team outperformed both human or autonomy working along. But how were they able to achieve this? We hypothesize that this is because the sliding autonomy approach enabled the human to focus on what the human is good at and autonomy to focus on what autonomy is good at. Bradshaw et al.\ point out~\cite{Bradshaw2013Seven}: ``Humans, though fallible, are functionally rich in reasoning strategies and their powers of observation, learning, and sensitivity to context.'' Our observation suggests that a human may be better equipped than autonomy to think strategically and to recognize bad path segments.

The sliding autonomy method lets the user plan at a higher abstract level by specifying priorities in search sub-regions and how well each sub-region should be covered. Autonomy, on the other hand can generate a path that covers a sub-region (or some nearby sub-regions) precisely and quickly, and can handle all kinds of irregular sub-region shapes. Therefore, the sliding autonomy method combines the strengths of both human and autonomy.

A human user is also very good at recognizing bad moves in solutions suggested by autonomy. The sliding autonomy approach enables the human user to select from a bunch of suggested paths. Selecting a path segment with fewer bad moves will probably increase the chance of a good final path.

%===================================================
\subsection{Why Similar Secondary Task Performance in All Three Methods?}

The pattern and sliding autonomy methods are episodic, suggesting that it is easier for the user to pause planning and shift attention to the secondary task of answering questions in the group chat window. However, user study data show that there is no significant differences in secondary task performance across all three path planning methods.

The manual method requires a lot of continuous keyboard interaction (great physical demand and temporal demand) to move the UAV around. However, it does not actually require much mental demand and effort because the planning process is more sporadic and spontaneous. If a mistake is made, because there is no way to correct it, the user quickly stops worrying about it and moves on. The low mental demand and effort make monitoring the group chat window an easy task, even though switching back and forth between primary task and secondary task is very frustrating.

With the pattern and sliding autonomy methods, path planning is more like piecing together a puzzle. The user is deeply drawn into problem solving, constantly comparing tradeoffs, which actually requires more mental involvement. With the sliding autonomy method, the user is interacting with complicated algorithms, so while planning a path, the user is also trying to build a mental model of how autonomy works. As a result, the user actually paid less attention to the secondary task. Fighting with autonomy when human and autonomy had disagreements also drew user attention away from the group chat window. But when the group chat window catches the user's attention, he/she can perform the secondary task leisurely.

David Woods and Eric Hollnagel describe the law of stretched systems~\cite{Woods2006Joint}: ''every system is stretched to operate at its capacity; as soon as there is some improvement, for example in the form of new technology, it will be exploited to achieve a new intensity and tempo of activity.'' With the pattern and sliding autonomy methods, users had more tries and evaluated more options and tradeoffs. With the sliding autonomy method, users played more with spatial and temporal constraints, and evaluated more paths suggested by path planning autonomy, which resulted in better quality paths at the cost of no performance increase in the secondary task.

%%===================================================
%\subsection{Fighting with Human Nature}
%
%It seems buried deeply in human nature that when a user performs an action, he/she wants immediate feedback so badly that when no such feedback is available, he/she cannot fight the urge to perform more actions thinking the additional actions would generate some feedback. To meet this demand, when we designed the sliding autonomy interface, we implemented two sliders where the second slider sets the step size value of the first slider. We had hoped that this would reduce the number of paths we had to pre-compute and make the user experience smoother by providing instant path feedback when they move the first slider. Observations from the user study show that this design actually negatively affected the user experience and increased user's cognitive workload. Which also means a better design with this element could potentially improve the user's performance and preference with the sliding autonomy method.
%
%Because when the value of the second slider is changed, the value of the first slider is also changed to reflect the smallest number that is a multiple of the selected step value. This behavior created multiple problems. First, some users quickly learned that changing the value of the second slider also changes time allocation to the path planning task, and started using this slider to set time allocation instead. This meant that more paths actually had to be pre-computed behind the scene, and in the user's eyes now the system was no longer providing instant feedback. So he/she began moving the slider randomly with the hope to generate some feedback, which meant more paths had to be pre-computed. A very bad cycle. Secondly, even though during training each user is told that there might be slight delay when they move the main slider in some cases, in the real exercises, they still wanted instant feedback. And when instant feedback was not available, they fell in the trap of operator-induced oscillation, and had to make several tries to set the value they desire. Fighting with the sliders required additional attention, so less attention were paid to monitor the group chat window. A ``please wait'' message would probably have less negative impact on the user's experience.
%
%When a human sees an ``obvious error'' in a path segment, the urge to correct is typically so strong that it draws all the attention to the quest, turning the path planning task into a fight with autonomy at the cost of increased cognitive workload. The ``obvious error'' could mean two different cases. In the first case, the ``error'' is indeed a bad move that can be easily modified in the user's mind to improve the path performance. In the second case, the ``error'' is actually not a bad move, only that the user cannot comprehend the reason behind the move, so there is still a strong desire to change it. However, because there is no direct way for the user to modify the path, the user can only change the path by moving the slider to set different time allocation, sometimes this ``error'' simply cannot be modified. The user wastes time trying, user's cognitive workload increases, and the user has a bad experience with the sliding autonomy method.
%
%There are probably more things than what we discussed here that could have improved the user experience and improve the user's performance on both the primary task of path planning and the secondary task of answering questions in the group chat window. We just want to emphasize that even with these negative impacts, the sliding autonomy method still performed significantly better than the other two methods and autonomy working alone without increasing the user's mental workload.

%=================================================================================	
\section{Conclusions and Future Work} 
\label{sec:Conclusions6}

In this paper we propose a new autonomy management approach, sliding autonomy, which lets the user influence the behavior of the autonomous system along three new dimensions: information representation, spatial constraints, and temporal constraints. We extend the autonomy design guidelines in our prior work by adding a new row for intelligence of collaborative agents (human-autonomy team), and explain how the three new dimensions fit into the guidelines when we apply the proposed approach to the task of UAV (Unmanned Aerial Vehicle) path planning to support Wilderness Search and Rescue (WiSAR). We present interface designs that let the user allocate degrees of authority and flexibility to the robot's algorithms through interactivities along these new dimensions. Experiment results from a user study support our hypotheses and show that the sliding autonomy method performs significantly better than either the manual or pattern path planning method without increasing the user's mental workload, the human has a better interaction experience, and human-autonomy team outperforms either human or autonomy working alone.

Over- and under-reliance on autonomy are related to issues of trust.  Both Lee and See~\cite{Lee2004Trust} and Bradshaw et al.\ \cite{Bradshaw2013Seven} suggest that trust in automation should be ``calibrated''. We believe that the sliding autonomy approach we propose can be useful in this aspect, because as the user is moving the slider, he/she is calibrating his/her reliance on path planning autonomy. In our user study, all participants only had 30 minutes of training before using the sliding autonomy method. We speculate that as the user gets more familiar with the sliding autonomy approach in the long run, he/she would be able to calibrate reliance better. Validating this hypothesis is a natural extension of the present work.

When more complex and/or outdated probability distribution maps and task-difficulty maps are used, or when the user has the ability to modify information representation in the sliding autonomy interface, it would be interesting to see how these affects the human-autonomy interaction and the performance of the human-autonomy team. We leave these for future work.

%=================================================================================	
\section*{Acknowledgments}

This work was partially supported by 
the National Science Foundation 
%\_\_\_\_\
under grant number 
0534736 and \_\_\_\_\_, 
%\_\_\_\_\_
and under the Robotics Collaborative Technology Alliance supported by the Army Research Laboratory. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsoring organizations.

\bibliography{LannyDissertation}

\hrule
\vspace*{.1in}
Authors' names and contact information: 

Lanny Lin, Brigham Young University, Provo, UT, USA.  Email: lanny@lannyland.com.  

Michael A. Goodrich, Brigham Young University, Provo, UT, USA.  Email: mike@cs.byu.edu.

Spencer Clark, Brigham Young University, Provo, UT, USA.  Email: spengy@gmail.com.

\end{document}

